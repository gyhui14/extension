/home/yunhui/anaconda2/lib/python2.7/site-packages/torch/serialization.py:425: SourceChangeWarning: source code of class 'models.resnet_block_format.ResNet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
main.py:112: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], labels.size(0))
Epoch [0/110]	Batch [0/120]	Loss 5.7084 (5.7084)	Prec@1 0.0000 (0.0000)
Epoch [0/110]	Batch [10/120]	Loss 6.4537 (5.9545)	Prec@1 0.0000 (0.2841)
Epoch [0/110]	Batch [20/120]	Loss 6.1985 (6.1155)	Prec@1 0.0000 (0.2232)
Epoch [0/110]	Batch [30/120]	Loss 6.1404 (6.1801)	Prec@1 0.0000 (0.4032)
Epoch [0/110]	Batch [40/120]	Loss 6.3017 (6.2259)	Prec@1 0.0000 (0.3049)
Epoch [0/110]	Batch [50/120]	Loss 6.2082 (6.2435)	Prec@1 1.5625 (0.3370)
Epoch [0/110]	Batch [60/120]	Loss 6.1096 (6.2297)	Prec@1 1.5625 (0.4355)
Epoch [0/110]	Batch [70/120]	Loss 5.7677 (6.1872)	Prec@1 0.0000 (0.3961)
Epoch [0/110]	Batch [80/120]	Loss 5.7843 (6.1669)	Prec@1 0.0000 (0.3858)
Epoch [0/110]	Batch [90/120]	Loss 5.7573 (6.1292)	Prec@1 0.0000 (0.3949)
Epoch [0/110]	Batch [100/120]	Loss 5.7331 (6.0905)	Prec@1 0.0000 (0.3713)
Epoch [0/110]	Batch [110/120]	Loss 5.6398 (6.0510)	Prec@1 0.0000 (0.4223)
Training Time 86.0245778561
main.py:191: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], labels.size(0))
test accuracy
Epoch [0/110]	Loss 5.5025 (5.9583)	Prec@1 1.5625 (0.9961)
Saving..
Epoch [1/110]	Batch [0/120]	Loss 5.5366 (5.5366)	Prec@1 1.5625 (1.5625)
Epoch [1/110]	Batch [10/120]	Loss 5.4941 (5.5450)	Prec@1 1.5625 (0.5682)
Epoch [1/110]	Batch [20/120]	Loss 5.5166 (5.5753)	Prec@1 0.0000 (1.2649)
Epoch [1/110]	Batch [30/120]	Loss 5.5780 (5.5657)	Prec@1 1.5625 (1.0585)
Epoch [1/110]	Batch [40/120]	Loss 5.4528 (5.5601)	Prec@1 1.5625 (1.0671)
Epoch [1/110]	Batch [50/120]	Loss 5.4180 (5.5578)	Prec@1 0.0000 (1.1336)
Epoch [1/110]	Batch [60/120]	Loss 5.5496 (5.5526)	Prec@1 0.0000 (1.1270)
Epoch [1/110]	Batch [70/120]	Loss 5.5136 (5.5437)	Prec@1 0.0000 (1.2104)
Epoch [1/110]	Batch [80/120]	Loss 5.2678 (5.5344)	Prec@1 3.1250 (1.3310)
Epoch [1/110]	Batch [90/120]	Loss 5.4244 (5.5271)	Prec@1 0.0000 (1.2706)
Epoch [1/110]	Batch [100/120]	Loss 5.5479 (5.5220)	Prec@1 1.5625 (1.2531)
Epoch [1/110]	Batch [110/120]	Loss 5.4835 (5.5169)	Prec@1 4.6875 (1.3232)
Training Time 71.6533648968
test accuracy
Epoch [1/110]	Loss 5.6720 (5.5544)	Prec@1 1.5625 (1.9531)
Saving..
Epoch [2/110]	Batch [0/120]	Loss 5.1938 (5.1938)	Prec@1 4.6875 (4.6875)
Epoch [2/110]	Batch [10/120]	Loss 5.4768 (5.3674)	Prec@1 0.0000 (1.9886)
Epoch [2/110]	Batch [20/120]	Loss 5.3806 (5.3629)	Prec@1 4.6875 (2.0089)
Epoch [2/110]	Batch [30/120]	Loss 5.4994 (5.3843)	Prec@1 0.0000 (1.8649)
Epoch [2/110]	Batch [40/120]	Loss 5.1933 (5.3710)	Prec@1 4.6875 (1.8674)
Epoch [2/110]	Batch [50/120]	Loss 5.2821 (5.3646)	Prec@1 1.5625 (1.8689)
Epoch [2/110]	Batch [60/120]	Loss 5.4634 (5.3730)	Prec@1 6.2500 (1.9467)
Epoch [2/110]	Batch [70/120]	Loss 5.4600 (5.3658)	Prec@1 0.0000 (1.9146)
Epoch [2/110]	Batch [80/120]	Loss 5.2536 (5.3616)	Prec@1 1.5625 (1.8904)
Epoch [2/110]	Batch [90/120]	Loss 5.0993 (5.3566)	Prec@1 9.3750 (2.0261)
Epoch [2/110]	Batch [100/120]	Loss 5.2698 (5.3499)	Prec@1 0.0000 (1.9493)
Epoch [2/110]	Batch [110/120]	Loss 5.3735 (5.3477)	Prec@1 0.0000 (1.9285)
Training Time 69.4534440041
test accuracy
Epoch [2/110]	Loss 6.5029 (5.5555)	Prec@1 1.5625 (2.3047)
Saving..
Epoch [3/110]	Batch [0/120]	Loss 5.1495 (5.1495)	Prec@1 3.1250 (3.1250)
Epoch [3/110]	Batch [10/120]	Loss 5.1658 (5.2280)	Prec@1 4.6875 (2.9830)
Epoch [3/110]	Batch [20/120]	Loss 5.2253 (5.2206)	Prec@1 1.5625 (3.0506)
Epoch [3/110]	Batch [30/120]	Loss 5.4699 (5.2373)	Prec@1 0.0000 (2.5202)
Epoch [3/110]	Batch [40/120]	Loss 5.1927 (5.2334)	Prec@1 0.0000 (2.4771)
Epoch [3/110]	Batch [50/120]	Loss 5.3458 (5.2340)	Prec@1 1.5625 (2.3897)
Epoch [3/110]	Batch [60/120]	Loss 5.2658 (5.2418)	Prec@1 0.0000 (2.3053)
Epoch [3/110]	Batch [70/120]	Loss 5.1814 (5.2406)	Prec@1 4.6875 (2.1787)
Epoch [3/110]	Batch [80/120]	Loss 5.2854 (5.2438)	Prec@1 1.5625 (2.1412)
Epoch [3/110]	Batch [90/120]	Loss 5.2680 (5.2412)	Prec@1 0.0000 (2.1806)
Epoch [3/110]	Batch [100/120]	Loss 5.1269 (5.2390)	Prec@1 1.5625 (2.2432)
Epoch [3/110]	Batch [110/120]	Loss 5.2764 (5.2396)	Prec@1 4.6875 (2.2804)
Training Time 68.549464941
test accuracy
Epoch [3/110]	Loss 5.2301 (5.3581)	Prec@1 4.6875 (2.8125)
Saving..
Epoch [4/110]	Batch [0/120]	Loss 5.0762 (5.0762)	Prec@1 3.1250 (3.1250)
Epoch [4/110]	Batch [10/120]	Loss 5.2127 (5.1212)	Prec@1 1.5625 (3.8352)
Epoch [4/110]	Batch [20/120]	Loss 5.2351 (5.1525)	Prec@1 4.6875 (3.2738)
Epoch [4/110]	Batch [30/120]	Loss 5.1495 (5.1578)	Prec@1 1.5625 (2.9738)
Epoch [4/110]	Batch [40/120]	Loss 5.0860 (5.1533)	Prec@1 4.6875 (3.3155)
Epoch [4/110]	Batch [50/120]	Loss 5.1414 (5.1655)	Prec@1 0.0000 (3.0944)
Epoch [4/110]	Batch [60/120]	Loss 5.1236 (5.1772)	Prec@1 0.0000 (2.9457)
Epoch [4/110]	Batch [70/120]	Loss 5.2866 (5.1752)	Prec@1 0.0000 (2.7729)
Epoch [4/110]	Batch [80/120]	Loss 5.4068 (5.1784)	Prec@1 3.1250 (2.7585)
Epoch [4/110]	Batch [90/120]	Loss 5.0676 (5.1792)	Prec@1 7.8125 (2.6786)
Epoch [4/110]	Batch [100/120]	Loss 5.0645 (5.1762)	Prec@1 1.5625 (2.6918)
Epoch [4/110]	Batch [110/120]	Loss 5.2184 (5.1688)	Prec@1 0.0000 (2.7168)
Training Time 68.7047700882
test accuracy
Epoch [4/110]	Loss 5.7751 (6.6369)	Prec@1 1.5625 (3.4766)
Saving..
Epoch [5/110]	Batch [0/120]	Loss 4.8768 (4.8768)	Prec@1 9.3750 (9.3750)
Epoch [5/110]	Batch [10/120]	Loss 5.1849 (5.0578)	Prec@1 4.6875 (4.9716)
Epoch [5/110]	Batch [20/120]	Loss 5.1468 (5.0853)	Prec@1 4.6875 (4.1667)
Epoch [5/110]	Batch [30/120]	Loss 5.2389 (5.1073)	Prec@1 6.2500 (3.6794)
Epoch [5/110]	Batch [40/120]	Loss 4.9381 (5.1056)	Prec@1 1.5625 (3.2012)
Epoch [5/110]	Batch [50/120]	Loss 4.9793 (5.1130)	Prec@1 4.6875 (3.1863)
Epoch [5/110]	Batch [60/120]	Loss 5.0552 (5.1146)	Prec@1 6.2500 (3.1506)
Epoch [5/110]	Batch [70/120]	Loss 5.2329 (5.1131)	Prec@1 1.5625 (3.1690)
Epoch [5/110]	Batch [80/120]	Loss 5.2918 (5.1154)	Prec@1 3.1250 (3.1250)
Epoch [5/110]	Batch [90/120]	Loss 5.1328 (5.1207)	Prec@1 3.1250 (3.0735)
Epoch [5/110]	Batch [100/120]	Loss 5.2268 (5.1163)	Prec@1 3.1250 (3.1869)
Epoch [5/110]	Batch [110/120]	Loss 5.0758 (5.1151)	Prec@1 1.5625 (3.2517)
Training Time 68.9328432083
test accuracy
Epoch [5/110]	Loss 5.2563 (5.2020)	Prec@1 4.6875 (4.1406)
Saving..
Epoch [6/110]	Batch [0/120]	Loss 5.0821 (5.0821)	Prec@1 7.8125 (7.8125)
Epoch [6/110]	Batch [10/120]	Loss 5.1115 (5.0848)	Prec@1 4.6875 (4.2614)
Epoch [6/110]	Batch [20/120]	Loss 4.9117 (5.0765)	Prec@1 3.1250 (3.9435)
Epoch [6/110]	Batch [30/120]	Loss 5.1237 (5.0788)	Prec@1 3.1250 (3.5282)
Epoch [6/110]	Batch [40/120]	Loss 4.8484 (5.0773)	Prec@1 7.8125 (3.4299)
Epoch [6/110]	Batch [50/120]	Loss 5.2142 (5.0771)	Prec@1 3.1250 (3.6152)
Epoch [6/110]	Batch [60/120]	Loss 5.0752 (5.0748)	Prec@1 4.6875 (3.8934)
Epoch [6/110]	Batch [70/120]	Loss 4.8932 (5.0731)	Prec@1 3.1250 (3.9613)
Epoch [6/110]	Batch [80/120]	Loss 5.0734 (5.0606)	Prec@1 6.2500 (4.0316)
Epoch [6/110]	Batch [90/120]	Loss 5.1417 (5.0629)	Prec@1 3.1250 (4.0522)
Epoch [6/110]	Batch [100/120]	Loss 5.1078 (5.0672)	Prec@1 6.2500 (3.9913)
Epoch [6/110]	Batch [110/120]	Loss 4.9896 (5.0630)	Prec@1 3.1250 (3.9696)
Training Time 69.0706458092
test accuracy
Epoch [6/110]	Loss 5.0676 (5.3600)	Prec@1 3.1250 (4.6484)
Saving..
Epoch [7/110]	Batch [0/120]	Loss 4.7819 (4.7819)	Prec@1 6.2500 (6.2500)
Epoch [7/110]	Batch [10/120]	Loss 4.9741 (5.0329)	Prec@1 3.1250 (3.8352)
Epoch [7/110]	Batch [20/120]	Loss 4.8811 (4.9984)	Prec@1 7.8125 (3.8690)
Epoch [7/110]	Batch [30/120]	Loss 4.9816 (4.9997)	Prec@1 1.5625 (3.9315)
Epoch [7/110]	Batch [40/120]	Loss 5.0291 (4.9997)	Prec@1 3.1250 (3.9634)
Epoch [7/110]	Batch [50/120]	Loss 4.6643 (5.0030)	Prec@1 7.8125 (4.0135)
Epoch [7/110]	Batch [60/120]	Loss 5.1648 (4.9914)	Prec@1 1.5625 (4.3289)
Epoch [7/110]	Batch [70/120]	Loss 4.8797 (4.9983)	Prec@1 3.1250 (4.1373)
Epoch [7/110]	Batch [80/120]	Loss 5.2439 (5.0046)	Prec@1 0.0000 (4.1088)
Epoch [7/110]	Batch [90/120]	Loss 5.1293 (5.0041)	Prec@1 3.1250 (4.0865)
Epoch [7/110]	Batch [100/120]	Loss 4.7581 (5.0000)	Prec@1 4.6875 (4.1460)
Epoch [7/110]	Batch [110/120]	Loss 4.7522 (4.9904)	Prec@1 7.8125 (4.3637)
Training Time 68.5630209446
test accuracy
Epoch [7/110]	Loss 5.0650 (5.8360)	Prec@1 1.5625 (5.0000)
Saving..
Epoch [8/110]	Batch [0/120]	Loss 4.7514 (4.7514)	Prec@1 4.6875 (4.6875)
Epoch [8/110]	Batch [10/120]	Loss 4.9959 (4.9146)	Prec@1 4.6875 (3.8352)
Epoch [8/110]	Batch [20/120]	Loss 4.6105 (4.8980)	Prec@1 9.3750 (4.6131)
Epoch [8/110]	Batch [30/120]	Loss 5.2808 (4.9060)	Prec@1 1.5625 (5.1915)
Epoch [8/110]	Batch [40/120]	Loss 5.0693 (4.9264)	Prec@1 1.5625 (4.7637)
Epoch [8/110]	Batch [50/120]	Loss 4.9044 (4.9270)	Prec@1 3.1250 (4.5650)
Epoch [8/110]	Batch [60/120]	Loss 5.1436 (4.9252)	Prec@1 4.6875 (4.6875)
Epoch [8/110]	Batch [70/120]	Loss 5.1672 (4.9265)	Prec@1 0.0000 (4.8415)
Epoch [8/110]	Batch [80/120]	Loss 4.9040 (4.9277)	Prec@1 1.5625 (4.9576)
Epoch [8/110]	Batch [90/120]	Loss 4.6198 (4.9209)	Prec@1 9.3750 (4.8935)
Epoch [8/110]	Batch [100/120]	Loss 4.8602 (4.9248)	Prec@1 4.6875 (4.9350)
Epoch [8/110]	Batch [110/120]	Loss 4.9504 (4.9284)	Prec@1 3.1250 (4.8705)
Training Time 69.253015995
test accuracy
Epoch [8/110]	Loss 4.6294 (5.7709)	Prec@1 9.3750 (6.4453)
Saving..
Epoch [9/110]	Batch [0/120]	Loss 4.6650 (4.6650)	Prec@1 10.9375 (10.9375)
Epoch [9/110]	Batch [10/120]	Loss 4.8577 (4.8188)	Prec@1 3.1250 (4.6875)
Epoch [9/110]	Batch [20/120]	Loss 5.2248 (4.8409)	Prec@1 3.1250 (4.5387)
Epoch [9/110]	Batch [30/120]	Loss 4.9518 (4.8337)	Prec@1 0.0000 (4.7379)
Epoch [9/110]	Batch [40/120]	Loss 5.0160 (4.8399)	Prec@1 6.2500 (5.0305)
Epoch [9/110]	Batch [50/120]	Loss 4.9299 (4.8499)	Prec@1 6.2500 (5.2083)
Epoch [9/110]	Batch [60/120]	Loss 4.9079 (4.8468)	Prec@1 3.1250 (5.1998)
Epoch [9/110]	Batch [70/120]	Loss 4.7523 (4.8388)	Prec@1 6.2500 (5.3477)
Epoch [9/110]	Batch [80/120]	Loss 4.8360 (4.8319)	Prec@1 10.9375 (5.4012)
Epoch [9/110]	Batch [90/120]	Loss 4.7785 (4.8378)	Prec@1 6.2500 (5.4430)
Epoch [9/110]	Batch [100/120]	Loss 5.0434 (4.8490)	Prec@1 1.5625 (5.3218)
Epoch [9/110]	Batch [110/120]	Loss 4.9734 (4.8534)	Prec@1 3.1250 (5.3350)
Training Time 69.4860570431
test accuracy
Epoch [9/110]	Loss 5.3229 (5.0253)	Prec@1 7.8125 (6.5430)
Saving..
Epoch [10/110]	Batch [0/120]	Loss 4.5555 (4.5555)	Prec@1 9.3750 (9.3750)
Epoch [10/110]	Batch [10/120]	Loss 4.9241 (4.7878)	Prec@1 6.2500 (6.5341)
Epoch [10/110]	Batch [20/120]	Loss 4.5012 (4.7561)	Prec@1 12.5000 (6.3988)
Epoch [10/110]	Batch [30/120]	Loss 4.8385 (4.7693)	Prec@1 3.1250 (6.1492)
Epoch [10/110]	Batch [40/120]	Loss 4.7526 (4.7638)	Prec@1 9.3750 (6.3643)
Epoch [10/110]	Batch [50/120]	Loss 4.7832 (4.7752)	Prec@1 9.3750 (6.3725)
Epoch [10/110]	Batch [60/120]	Loss 4.8553 (4.7941)	Prec@1 6.2500 (6.1732)
Epoch [10/110]	Batch [70/120]	Loss 5.1069 (4.7941)	Prec@1 6.2500 (6.2280)
Epoch [10/110]	Batch [80/120]	Loss 5.0799 (4.8061)	Prec@1 0.0000 (6.1150)
Epoch [10/110]	Batch [90/120]	Loss 4.7107 (4.8031)	Prec@1 6.2500 (6.1985)
Epoch [10/110]	Batch [100/120]	Loss 4.6811 (4.7999)	Prec@1 6.2500 (6.2500)
Epoch [10/110]	Batch [110/120]	Loss 4.8016 (4.7966)	Prec@1 10.9375 (6.3908)
Training Time 68.9000999928
test accuracy
Epoch [10/110]	Loss 4.4923 (6.0699)	Prec@1 12.5000 (7.5781)
Saving..
Epoch [11/110]	Batch [0/120]	Loss 4.6877 (4.6877)	Prec@1 7.8125 (7.8125)
Epoch [11/110]	Batch [10/120]	Loss 4.8252 (4.7352)	Prec@1 4.6875 (5.9659)
Epoch [11/110]	Batch [20/120]	Loss 5.0054 (4.7405)	Prec@1 3.1250 (5.9524)
Epoch [11/110]	Batch [30/120]	Loss 4.6999 (4.7143)	Prec@1 6.2500 (6.5020)
Epoch [11/110]	Batch [40/120]	Loss 4.5299 (4.7145)	Prec@1 7.8125 (6.6692)
Epoch [11/110]	Batch [50/120]	Loss 4.7780 (4.7296)	Prec@1 7.8125 (6.6483)
Epoch [11/110]	Batch [60/120]	Loss 4.7652 (4.7381)	Prec@1 9.3750 (6.8648)
Epoch [11/110]	Batch [70/120]	Loss 4.7404 (4.7435)	Prec@1 6.2500 (6.8662)
Epoch [11/110]	Batch [80/120]	Loss 4.3972 (4.7374)	Prec@1 12.5000 (6.9830)
Epoch [11/110]	Batch [90/120]	Loss 4.7715 (4.7423)	Prec@1 4.6875 (6.8681)
Epoch [11/110]	Batch [100/120]	Loss 4.7027 (4.7406)	Prec@1 7.8125 (6.7915)
Epoch [11/110]	Batch [110/120]	Loss 4.6561 (4.7473)	Prec@1 6.2500 (6.7708)
Training Time 69.6966278553
test accuracy
Epoch [11/110]	Loss 5.3272 (5.4076)	Prec@1 6.2500 (6.5234)
Epoch [12/110]	Batch [0/120]	Loss 4.4590 (4.4590)	Prec@1 6.2500 (6.2500)
Epoch [12/110]	Batch [10/120]	Loss 4.5764 (4.6342)	Prec@1 4.6875 (5.9659)
Epoch [12/110]	Batch [20/120]	Loss 4.5462 (4.6711)	Prec@1 12.5000 (6.3988)
Epoch [12/110]	Batch [30/120]	Loss 4.5907 (4.6761)	Prec@1 14.0625 (6.9556)
Epoch [12/110]	Batch [40/120]	Loss 4.3989 (4.6665)	Prec@1 12.5000 (7.2027)
Epoch [12/110]	Batch [50/120]	Loss 4.6130 (4.6645)	Prec@1 4.6875 (7.1691)
Epoch [12/110]	Batch [60/120]	Loss 5.0106 (4.6621)	Prec@1 6.2500 (7.2490)
Epoch [12/110]	Batch [70/120]	Loss 4.5422 (4.6580)	Prec@1 7.8125 (7.7025)
Epoch [12/110]	Batch [80/120]	Loss 4.6665 (4.6622)	Prec@1 9.3750 (7.7160)
Epoch [12/110]	Batch [90/120]	Loss 4.8370 (4.6725)	Prec@1 4.6875 (7.5893)
Epoch [12/110]	Batch [100/120]	Loss 4.9198 (4.6810)	Prec@1 3.1250 (7.5340)
Epoch [12/110]	Batch [110/120]	Loss 4.7644 (4.6889)	Prec@1 9.3750 (7.5028)
Training Time 69.881016016
test accuracy
Epoch [12/110]	Loss 4.8258 (4.8718)	Prec@1 6.2500 (7.7148)
Saving..
Epoch [13/110]	Batch [0/120]	Loss 4.8444 (4.8444)	Prec@1 1.5625 (1.5625)
Epoch [13/110]	Batch [10/120]	Loss 4.5704 (4.6359)	Prec@1 6.2500 (7.1023)
Epoch [13/110]	Batch [20/120]	Loss 4.9547 (4.6125)	Prec@1 7.8125 (7.9613)
Epoch [13/110]	Batch [30/120]	Loss 4.5410 (4.6168)	Prec@1 10.9375 (7.5605)
Epoch [13/110]	Batch [40/120]	Loss 4.5783 (4.6158)	Prec@1 12.5000 (7.6220)
Epoch [13/110]	Batch [50/120]	Loss 4.8617 (4.6198)	Prec@1 6.2500 (7.6287)
Epoch [13/110]	Batch [60/120]	Loss 4.6978 (4.6239)	Prec@1 9.3750 (7.6076)
Epoch [13/110]	Batch [70/120]	Loss 4.9455 (4.6288)	Prec@1 4.6875 (7.3944)
Epoch [13/110]	Batch [80/120]	Loss 4.7223 (4.6361)	Prec@1 3.1250 (7.3688)
Epoch [13/110]	Batch [90/120]	Loss 4.7011 (4.6487)	Prec@1 3.1250 (7.2802)
Epoch [13/110]	Batch [100/120]	Loss 4.4335 (4.6500)	Prec@1 12.5000 (7.3329)
Epoch [13/110]	Batch [110/120]	Loss 4.4977 (4.6473)	Prec@1 9.3750 (7.3620)
Training Time 68.5927231312
test accuracy
Epoch [13/110]	Loss 7.5150 (5.9998)	Prec@1 7.8125 (8.3984)
Saving..
Epoch [14/110]	Batch [0/120]	Loss 4.1476 (4.1476)	Prec@1 17.1875 (17.1875)
Epoch [14/110]	Batch [10/120]	Loss 4.0493 (4.4730)	Prec@1 9.3750 (8.6648)
Epoch [14/110]	Batch [20/120]	Loss 4.5238 (4.5519)	Prec@1 6.2500 (8.2589)
Epoch [14/110]	Batch [30/120]	Loss 4.4197 (4.5386)	Prec@1 10.9375 (8.3669)
Epoch [14/110]	Batch [40/120]	Loss 4.6526 (4.5667)	Prec@1 7.8125 (8.3841)
Epoch [14/110]	Batch [50/120]	Loss 4.6900 (4.5611)	Prec@1 9.3750 (8.7316)
Epoch [14/110]	Batch [60/120]	Loss 4.2416 (4.5681)	Prec@1 14.0625 (8.5297)
Epoch [14/110]	Batch [70/120]	Loss 4.6939 (4.5733)	Prec@1 10.9375 (8.4727)
Epoch [14/110]	Batch [80/120]	Loss 4.5050 (4.5800)	Prec@1 7.8125 (8.5069)
Epoch [14/110]	Batch [90/120]	Loss 4.4397 (4.5799)	Prec@1 10.9375 (8.4478)
Epoch [14/110]	Batch [100/120]	Loss 4.3036 (4.5590)	Prec@1 17.1875 (8.6634)
Epoch [14/110]	Batch [110/120]	Loss 4.5238 (4.5693)	Prec@1 14.0625 (8.7134)
Training Time 67.65335989
test accuracy
Epoch [14/110]	Loss 4.6089 (5.3484)	Prec@1 9.3750 (8.6133)
Saving..
Epoch [15/110]	Batch [0/120]	Loss 4.6257 (4.6257)	Prec@1 4.6875 (4.6875)
Epoch [15/110]	Batch [10/120]	Loss 4.6186 (4.5241)	Prec@1 9.3750 (8.9489)
Epoch [15/110]	Batch [20/120]	Loss 4.5605 (4.5229)	Prec@1 4.6875 (8.3333)
Epoch [15/110]	Batch [30/120]	Loss 4.5759 (4.5255)	Prec@1 12.5000 (8.5685)
Epoch [15/110]	Batch [40/120]	Loss 4.6868 (4.5060)	Prec@1 9.3750 (8.7652)
Epoch [15/110]	Batch [50/120]	Loss 4.5420 (4.4891)	Prec@1 7.8125 (8.9461)
Epoch [15/110]	Batch [60/120]	Loss 4.6061 (4.4906)	Prec@1 10.9375 (9.1189)
Epoch [15/110]	Batch [70/120]	Loss 4.6484 (4.4980)	Prec@1 3.1250 (9.0889)
Epoch [15/110]	Batch [80/120]	Loss 4.5589 (4.5033)	Prec@1 7.8125 (8.9892)
Epoch [15/110]	Batch [90/120]	Loss 4.6332 (4.4931)	Prec@1 9.3750 (9.0316)
Epoch [15/110]	Batch [100/120]	Loss 4.5357 (4.5062)	Prec@1 9.3750 (8.9728)
Epoch [15/110]	Batch [110/120]	Loss 4.8856 (4.5105)	Prec@1 9.3750 (9.1357)
Training Time 68.122964859
test accuracy
Epoch [15/110]	Loss 5.6931 (5.0931)	Prec@1 6.2500 (10.4883)
Saving..
Epoch [16/110]	Batch [0/120]	Loss 4.6196 (4.6196)	Prec@1 14.0625 (14.0625)
Epoch [16/110]	Batch [10/120]	Loss 4.3871 (4.4052)	Prec@1 10.9375 (11.9318)
Epoch [16/110]	Batch [20/120]	Loss 4.6446 (4.4056)	Prec@1 10.9375 (11.6071)
Epoch [16/110]	Batch [30/120]	Loss 4.5274 (4.4458)	Prec@1 12.5000 (11.1895)
Epoch [16/110]	Batch [40/120]	Loss 4.3844 (4.4550)	Prec@1 4.6875 (10.5183)
Epoch [16/110]	Batch [50/120]	Loss 4.5858 (4.4533)	Prec@1 9.3750 (10.2328)
Epoch [16/110]	Batch [60/120]	Loss 4.5003 (4.4568)	Prec@1 12.5000 (10.2459)
Epoch [16/110]	Batch [70/120]	Loss 4.4121 (4.4451)	Prec@1 14.0625 (10.4533)
Epoch [16/110]	Batch [80/120]	Loss 4.1619 (4.4502)	Prec@1 7.8125 (10.1659)
Epoch [16/110]	Batch [90/120]	Loss 3.9731 (4.4490)	Prec@1 18.7500 (10.2163)
Epoch [16/110]	Batch [100/120]	Loss 4.3956 (4.4529)	Prec@1 14.0625 (10.1949)
Epoch [16/110]	Batch [110/120]	Loss 4.7103 (4.4602)	Prec@1 4.6875 (10.2337)
Training Time 68.5202379227
test accuracy
Epoch [16/110]	Loss 5.0218 (5.3045)	Prec@1 6.2500 (10.2930)
Epoch [17/110]	Batch [0/120]	Loss 4.6168 (4.6168)	Prec@1 14.0625 (14.0625)
Epoch [17/110]	Batch [10/120]	Loss 4.0990 (4.3277)	Prec@1 15.6250 (11.5057)
Epoch [17/110]	Batch [20/120]	Loss 4.2044 (4.3245)	Prec@1 10.9375 (12.5744)
Epoch [17/110]	Batch [30/120]	Loss 4.5114 (4.3329)	Prec@1 7.8125 (11.8448)
Epoch [17/110]	Batch [40/120]	Loss 4.5011 (4.3418)	Prec@1 4.6875 (11.8140)
Epoch [17/110]	Batch [50/120]	Loss 4.2506 (4.3624)	Prec@1 7.8125 (11.2745)
Epoch [17/110]	Batch [60/120]	Loss 4.4358 (4.3715)	Prec@1 10.9375 (11.1168)
Epoch [17/110]	Batch [70/120]	Loss 4.2065 (4.3863)	Prec@1 12.5000 (11.0475)
Epoch [17/110]	Batch [80/120]	Loss 4.5722 (4.3747)	Prec@1 9.3750 (11.2461)
Epoch [17/110]	Batch [90/120]	Loss 4.6880 (4.3788)	Prec@1 9.3750 (11.4183)
Epoch [17/110]	Batch [100/120]	Loss 4.5387 (4.3817)	Prec@1 7.8125 (11.4325)
Epoch [17/110]	Batch [110/120]	Loss 4.6585 (4.3901)	Prec@1 10.9375 (11.2613)
Training Time 68.9295339584
test accuracy
Epoch [17/110]	Loss 4.5142 (4.7833)	Prec@1 12.5000 (12.0312)
Saving..
Epoch [18/110]	Batch [0/120]	Loss 4.2447 (4.2447)	Prec@1 17.1875 (17.1875)
Epoch [18/110]	Batch [10/120]	Loss 3.8334 (4.2580)	Prec@1 12.5000 (11.7898)
Epoch [18/110]	Batch [20/120]	Loss 4.2537 (4.2590)	Prec@1 10.9375 (12.5744)
Epoch [18/110]	Batch [30/120]	Loss 4.4765 (4.2618)	Prec@1 9.3750 (12.6512)
Epoch [18/110]	Batch [40/120]	Loss 4.2430 (4.2606)	Prec@1 10.9375 (11.9284)
Epoch [18/110]	Batch [50/120]	Loss 4.6292 (4.2847)	Prec@1 10.9375 (11.8260)
Epoch [18/110]	Batch [60/120]	Loss 4.6870 (4.2967)	Prec@1 9.3750 (11.7316)
Epoch [18/110]	Batch [70/120]	Loss 4.1255 (4.3027)	Prec@1 14.0625 (11.8178)
Epoch [18/110]	Batch [80/120]	Loss 4.3002 (4.3133)	Prec@1 14.0625 (11.8248)
Epoch [18/110]	Batch [90/120]	Loss 4.2727 (4.3113)	Prec@1 10.9375 (11.8304)
Epoch [18/110]	Batch [100/120]	Loss 4.7391 (4.3310)	Prec@1 9.3750 (11.5254)
Epoch [18/110]	Batch [110/120]	Loss 4.1471 (4.3256)	Prec@1 15.6250 (11.6132)
Training Time 68.8715009689
test accuracy
Epoch [18/110]	Loss 4.8758 (5.0279)	Prec@1 10.9375 (11.0742)
Epoch [19/110]	Batch [0/120]	Loss 4.1886 (4.1886)	Prec@1 10.9375 (10.9375)
Epoch [19/110]	Batch [10/120]	Loss 4.0936 (4.2204)	Prec@1 15.6250 (12.9261)
Epoch [19/110]	Batch [20/120]	Loss 4.1481 (4.2552)	Prec@1 6.2500 (12.4256)
Epoch [19/110]	Batch [30/120]	Loss 4.2313 (4.2673)	Prec@1 12.5000 (12.0968)
Epoch [19/110]	Batch [40/120]	Loss 4.2694 (4.2562)	Prec@1 14.0625 (12.5381)
Epoch [19/110]	Batch [50/120]	Loss 4.0177 (4.2565)	Prec@1 14.0625 (12.3468)
Epoch [19/110]	Batch [60/120]	Loss 4.3685 (4.2622)	Prec@1 14.0625 (12.1414)
Epoch [19/110]	Batch [70/120]	Loss 4.2499 (4.2564)	Prec@1 15.6250 (12.1699)
Epoch [19/110]	Batch [80/120]	Loss 4.3050 (4.2574)	Prec@1 10.9375 (12.2878)
Epoch [19/110]	Batch [90/120]	Loss 4.2500 (4.2547)	Prec@1 9.3750 (12.3626)
Epoch [19/110]	Batch [100/120]	Loss 4.4591 (4.2518)	Prec@1 9.3750 (12.4845)
Epoch [19/110]	Batch [110/120]	Loss 4.5149 (4.2484)	Prec@1 10.9375 (12.4015)
Training Time 68.2638010979
test accuracy
Epoch [19/110]	Loss 5.0054 (4.7924)	Prec@1 15.6250 (13.2617)
Saving..
Epoch [20/110]	Batch [0/120]	Loss 4.1258 (4.1258)	Prec@1 12.5000 (12.5000)
Epoch [20/110]	Batch [10/120]	Loss 4.1518 (4.1880)	Prec@1 6.2500 (12.0739)
Epoch [20/110]	Batch [20/120]	Loss 4.1896 (4.2043)	Prec@1 15.6250 (12.2768)
Epoch [20/110]	Batch [30/120]	Loss 4.5998 (4.2436)	Prec@1 10.9375 (11.9456)
Epoch [20/110]	Batch [40/120]	Loss 4.2334 (4.2278)	Prec@1 17.1875 (12.7668)
Epoch [20/110]	Batch [50/120]	Loss 4.3496 (4.2308)	Prec@1 10.9375 (12.7145)
Epoch [20/110]	Batch [60/120]	Loss 4.1951 (4.2420)	Prec@1 9.3750 (12.4488)
Epoch [20/110]	Batch [70/120]	Loss 4.3138 (4.2426)	Prec@1 14.0625 (12.4780)
Epoch [20/110]	Batch [80/120]	Loss 4.4427 (4.2352)	Prec@1 7.8125 (12.5965)
Epoch [20/110]	Batch [90/120]	Loss 3.9950 (4.2177)	Prec@1 10.9375 (12.9979)
Epoch [20/110]	Batch [100/120]	Loss 4.1944 (4.2286)	Prec@1 15.6250 (12.9332)
Epoch [20/110]	Batch [110/120]	Loss 4.3491 (4.2324)	Prec@1 17.1875 (12.8801)
Training Time 68.389991045
test accuracy
Epoch [20/110]	Loss 4.4911 (6.3175)	Prec@1 17.1875 (12.9883)
Epoch [21/110]	Batch [0/120]	Loss 4.3265 (4.3265)	Prec@1 12.5000 (12.5000)
Epoch [21/110]	Batch [10/120]	Loss 4.1233 (4.0928)	Prec@1 15.6250 (15.9091)
Epoch [21/110]	Batch [20/120]	Loss 4.2271 (4.1162)	Prec@1 10.9375 (14.9554)
Epoch [21/110]	Batch [30/120]	Loss 4.4434 (4.1343)	Prec@1 12.5000 (14.8690)
Epoch [21/110]	Batch [40/120]	Loss 4.1242 (4.1530)	Prec@1 9.3750 (14.4817)
Epoch [21/110]	Batch [50/120]	Loss 3.9427 (4.1465)	Prec@1 17.1875 (14.8591)
Epoch [21/110]	Batch [60/120]	Loss 4.2264 (4.1325)	Prec@1 9.3750 (14.7029)
Epoch [21/110]	Batch [70/120]	Loss 4.3399 (4.1397)	Prec@1 20.3125 (14.8768)
Epoch [21/110]	Batch [80/120]	Loss 4.1652 (4.1328)	Prec@1 14.0625 (14.9306)
Epoch [21/110]	Batch [90/120]	Loss 4.2472 (4.1543)	Prec@1 10.9375 (14.4402)
Epoch [21/110]	Batch [100/120]	Loss 3.9690 (4.1551)	Prec@1 17.1875 (14.3410)
Epoch [21/110]	Batch [110/120]	Loss 4.2029 (4.1695)	Prec@1 10.9375 (14.1329)
Training Time 69.6958479881
test accuracy
Epoch [21/110]	Loss 4.4820 (4.5279)	Prec@1 9.3750 (13.3008)
Saving..
Epoch [22/110]	Batch [0/120]	Loss 4.2034 (4.2034)	Prec@1 15.6250 (15.6250)
Epoch [22/110]	Batch [10/120]	Loss 3.9288 (4.0837)	Prec@1 18.7500 (14.6307)
Epoch [22/110]	Batch [20/120]	Loss 4.1647 (4.0927)	Prec@1 9.3750 (14.2113)
Epoch [22/110]	Batch [30/120]	Loss 3.9932 (4.1072)	Prec@1 15.6250 (14.2641)
Epoch [22/110]	Batch [40/120]	Loss 3.9940 (4.1067)	Prec@1 14.0625 (14.1387)
Epoch [22/110]	Batch [50/120]	Loss 3.6645 (4.0932)	Prec@1 18.7500 (14.2770)
Epoch [22/110]	Batch [60/120]	Loss 4.1302 (4.0641)	Prec@1 18.7500 (14.6260)
Epoch [22/110]	Batch [70/120]	Loss 4.3330 (4.0824)	Prec@1 15.6250 (14.6127)
Epoch [22/110]	Batch [80/120]	Loss 4.3604 (4.0774)	Prec@1 12.5000 (14.6605)
Epoch [22/110]	Batch [90/120]	Loss 4.1687 (4.0862)	Prec@1 14.0625 (14.5261)
Epoch [22/110]	Batch [100/120]	Loss 4.2166 (4.0942)	Prec@1 12.5000 (14.2946)
Epoch [22/110]	Batch [110/120]	Loss 4.0367 (4.0964)	Prec@1 17.1875 (14.0625)
Training Time 69.4077131748
test accuracy
Epoch [22/110]	Loss 4.4211 (4.7901)	Prec@1 14.0625 (13.5938)
Saving..
Epoch [23/110]	Batch [0/120]	Loss 3.8739 (3.8739)	Prec@1 15.6250 (15.6250)
Epoch [23/110]	Batch [10/120]	Loss 4.2181 (3.9966)	Prec@1 12.5000 (16.0511)
Epoch [23/110]	Batch [20/120]	Loss 3.8096 (3.9963)	Prec@1 25.0000 (16.2946)
Epoch [23/110]	Batch [30/120]	Loss 3.8626 (4.0217)	Prec@1 21.8750 (15.8770)
Epoch [23/110]	Batch [40/120]	Loss 4.0002 (4.0352)	Prec@1 14.0625 (15.4345)
Epoch [23/110]	Batch [50/120]	Loss 4.2340 (4.0396)	Prec@1 12.5000 (15.0123)
Epoch [23/110]	Batch [60/120]	Loss 4.5779 (4.0610)	Prec@1 10.9375 (15.0102)
Epoch [23/110]	Batch [70/120]	Loss 3.9132 (4.0686)	Prec@1 21.8750 (14.7667)
Epoch [23/110]	Batch [80/120]	Loss 3.7214 (4.0616)	Prec@1 15.6250 (14.6219)
Epoch [23/110]	Batch [90/120]	Loss 3.9001 (4.0720)	Prec@1 20.3125 (14.4746)
Epoch [23/110]	Batch [100/120]	Loss 4.0587 (4.0690)	Prec@1 15.6250 (14.6504)
Epoch [23/110]	Batch [110/120]	Loss 3.8410 (4.0580)	Prec@1 21.8750 (14.8367)
Training Time 69.2659459114
test accuracy
Epoch [23/110]	Loss 4.5271 (5.5818)	Prec@1 21.8750 (13.4375)
Epoch [24/110]	Batch [0/120]	Loss 3.7768 (3.7768)	Prec@1 26.5625 (26.5625)
Epoch [24/110]	Batch [10/120]	Loss 3.7892 (3.9818)	Prec@1 14.0625 (14.3466)
Epoch [24/110]	Batch [20/120]	Loss 4.0209 (3.9801)	Prec@1 7.8125 (14.5833)
Epoch [24/110]	Batch [30/120]	Loss 4.1910 (3.9838)	Prec@1 15.6250 (14.6673)
Epoch [24/110]	Batch [40/120]	Loss 3.8974 (3.9977)	Prec@1 15.6250 (14.6341)
Epoch [24/110]	Batch [50/120]	Loss 4.0554 (4.0023)	Prec@1 15.6250 (14.9816)
Epoch [24/110]	Batch [60/120]	Loss 4.2625 (4.0149)	Prec@1 7.8125 (14.8566)
Epoch [24/110]	Batch [70/120]	Loss 3.8943 (4.0377)	Prec@1 23.4375 (14.8107)
Epoch [24/110]	Batch [80/120]	Loss 3.9558 (4.0393)	Prec@1 21.8750 (14.9498)
Epoch [24/110]	Batch [90/120]	Loss 3.7797 (4.0212)	Prec@1 20.3125 (15.3503)
Epoch [24/110]	Batch [100/120]	Loss 4.0666 (4.0271)	Prec@1 12.5000 (15.3775)
Epoch [24/110]	Batch [110/120]	Loss 3.8540 (4.0151)	Prec@1 21.8750 (15.5968)
Training Time 68.8986170292
test accuracy
Epoch [24/110]	Loss 4.4904 (6.2962)	Prec@1 10.9375 (11.7383)
Epoch [25/110]	Batch [0/120]	Loss 4.1239 (4.1239)	Prec@1 15.6250 (15.6250)
Epoch [25/110]	Batch [10/120]	Loss 3.8957 (3.9108)	Prec@1 14.0625 (16.0511)
Epoch [25/110]	Batch [20/120]	Loss 3.8248 (3.8538)	Prec@1 10.9375 (16.7411)
Epoch [25/110]	Batch [30/120]	Loss 3.0565 (3.8600)	Prec@1 23.4375 (16.5323)
Epoch [25/110]	Batch [40/120]	Loss 4.3157 (3.8863)	Prec@1 7.8125 (16.8064)
Epoch [25/110]	Batch [50/120]	Loss 3.6109 (3.8819)	Prec@1 18.7500 (17.3407)
Epoch [25/110]	Batch [60/120]	Loss 3.8550 (3.9139)	Prec@1 17.1875 (16.7777)
Epoch [25/110]	Batch [70/120]	Loss 3.8911 (3.9164)	Prec@1 15.6250 (16.4173)
Epoch [25/110]	Batch [80/120]	Loss 4.1904 (3.9281)	Prec@1 12.5000 (16.3194)
Epoch [25/110]	Batch [90/120]	Loss 4.0561 (3.9371)	Prec@1 15.6250 (16.1916)
Epoch [25/110]	Batch [100/120]	Loss 3.7266 (3.9370)	Prec@1 12.5000 (16.0891)
Epoch [25/110]	Batch [110/120]	Loss 4.0459 (3.9354)	Prec@1 14.0625 (16.1881)
Training Time 69.3475949764
test accuracy
Epoch [25/110]	Loss 6.6480 (6.5224)	Prec@1 21.8750 (15.5859)
Saving..
Epoch [26/110]	Batch [0/120]	Loss 4.0974 (4.0974)	Prec@1 18.7500 (18.7500)
Epoch [26/110]	Batch [10/120]	Loss 3.8664 (3.8511)	Prec@1 14.0625 (18.0398)
Epoch [26/110]	Batch [20/120]	Loss 3.7826 (3.8157)	Prec@1 25.0000 (18.2292)
Epoch [26/110]	Batch [30/120]	Loss 3.9584 (3.8406)	Prec@1 12.5000 (17.7419)
Epoch [26/110]	Batch [40/120]	Loss 3.8979 (3.8395)	Prec@1 10.9375 (17.7591)
Epoch [26/110]	Batch [50/120]	Loss 4.0496 (3.8500)	Prec@1 10.9375 (17.7083)
Epoch [26/110]	Batch [60/120]	Loss 3.8807 (3.8503)	Prec@1 18.7500 (17.6486)
Epoch [26/110]	Batch [70/120]	Loss 3.9609 (3.8747)	Prec@1 15.6250 (17.0555)
Epoch [26/110]	Batch [80/120]	Loss 3.8557 (3.8747)	Prec@1 20.3125 (16.9174)
Epoch [26/110]	Batch [90/120]	Loss 3.6716 (3.8619)	Prec@1 21.8750 (17.1703)
Epoch [26/110]	Batch [100/120]	Loss 3.9906 (3.8804)	Prec@1 23.4375 (17.0328)
Epoch [26/110]	Batch [110/120]	Loss 4.1940 (3.8733)	Prec@1 14.0625 (17.1875)
Training Time 69.2950630188
test accuracy
Epoch [26/110]	Loss 4.4740 (5.1043)	Prec@1 14.0625 (15.5664)
Epoch [27/110]	Batch [0/120]	Loss 3.8097 (3.8097)	Prec@1 12.5000 (12.5000)
Epoch [27/110]	Batch [10/120]	Loss 3.8662 (3.8036)	Prec@1 10.9375 (17.1875)
Epoch [27/110]	Batch [20/120]	Loss 4.0177 (3.8315)	Prec@1 12.5000 (17.5595)
Epoch [27/110]	Batch [30/120]	Loss 3.7995 (3.8270)	Prec@1 14.0625 (17.7419)
Epoch [27/110]	Batch [40/120]	Loss 3.5123 (3.7887)	Prec@1 20.3125 (18.7881)
Epoch [27/110]	Batch [50/120]	Loss 4.0626 (3.7981)	Prec@1 20.3125 (18.7806)
Epoch [27/110]	Batch [60/120]	Loss 3.6398 (3.8038)	Prec@1 15.6250 (18.5707)
Epoch [27/110]	Batch [70/120]	Loss 4.2503 (3.8193)	Prec@1 10.9375 (17.9577)
Epoch [27/110]	Batch [80/120]	Loss 3.8501 (3.8297)	Prec@1 18.7500 (17.9012)
Epoch [27/110]	Batch [90/120]	Loss 3.8115 (3.8342)	Prec@1 17.1875 (17.6339)
Epoch [27/110]	Batch [100/120]	Loss 3.8356 (3.8395)	Prec@1 9.3750 (17.5897)
Epoch [27/110]	Batch [110/120]	Loss 3.6828 (3.8395)	Prec@1 23.4375 (17.5676)
Training Time 69.359005928
test accuracy
Epoch [27/110]	Loss 4.6797 (5.4247)	Prec@1 17.1875 (15.7227)
Saving..
Epoch [28/110]	Batch [0/120]	Loss 3.6573 (3.6573)	Prec@1 20.3125 (20.3125)
Epoch [28/110]	Batch [10/120]	Loss 3.6123 (3.6911)	Prec@1 20.3125 (19.8864)
Epoch [28/110]	Batch [20/120]	Loss 3.5723 (3.7555)	Prec@1 23.4375 (18.6756)
Epoch [28/110]	Batch [30/120]	Loss 3.8768 (3.7315)	Prec@1 10.9375 (19.0524)
Epoch [28/110]	Batch [40/120]	Loss 4.2589 (3.7719)	Prec@1 10.9375 (18.1784)
Epoch [28/110]	Batch [50/120]	Loss 3.8358 (3.8053)	Prec@1 23.4375 (18.0453)
Epoch [28/110]	Batch [60/120]	Loss 3.6462 (3.8169)	Prec@1 21.8750 (17.7766)
Epoch [28/110]	Batch [70/120]	Loss 3.9027 (3.8166)	Prec@1 17.1875 (18.2879)
Epoch [28/110]	Batch [80/120]	Loss 3.8286 (3.8077)	Prec@1 15.6250 (18.2099)
Epoch [28/110]	Batch [90/120]	Loss 3.8467 (3.8038)	Prec@1 18.7500 (18.3379)
Epoch [28/110]	Batch [100/120]	Loss 3.7077 (3.8018)	Prec@1 18.7500 (18.3787)
Epoch [28/110]	Batch [110/120]	Loss 4.0173 (3.8084)	Prec@1 15.6250 (18.2714)
Training Time 68.938890934
test accuracy
Epoch [28/110]	Loss 4.4127 (4.8266)	Prec@1 15.6250 (15.1562)
Epoch [29/110]	Batch [0/120]	Loss 3.5965 (3.5965)	Prec@1 20.3125 (20.3125)
Epoch [29/110]	Batch [10/120]	Loss 3.5917 (3.6941)	Prec@1 23.4375 (20.1705)
Epoch [29/110]	Batch [20/120]	Loss 4.1624 (3.6772)	Prec@1 14.0625 (20.6101)
Epoch [29/110]	Batch [30/120]	Loss 3.3139 (3.6808)	Prec@1 32.8125 (20.3629)
Epoch [29/110]	Batch [40/120]	Loss 3.7438 (3.6828)	Prec@1 20.3125 (20.1220)
Epoch [29/110]	Batch [50/120]	Loss 3.6622 (3.6845)	Prec@1 17.1875 (20.2206)
Epoch [29/110]	Batch [60/120]	Loss 3.8838 (3.6816)	Prec@1 17.1875 (20.1076)
Epoch [29/110]	Batch [70/120]	Loss 3.4875 (3.6945)	Prec@1 18.7500 (19.7183)
Epoch [29/110]	Batch [80/120]	Loss 3.8909 (3.7081)	Prec@1 14.0625 (19.7531)
Epoch [29/110]	Batch [90/120]	Loss 3.9519 (3.7193)	Prec@1 12.5000 (19.4883)
Epoch [29/110]	Batch [100/120]	Loss 3.7249 (3.7242)	Prec@1 25.0000 (19.5545)
Epoch [29/110]	Batch [110/120]	Loss 3.4313 (3.7262)	Prec@1 29.6875 (19.4820)
Training Time 68.9940619469
test accuracy
Epoch [29/110]	Loss 4.9083 (6.9222)	Prec@1 15.6250 (17.4609)
Saving..
Epoch [30/110]	Batch [0/120]	Loss 3.5246 (3.5246)	Prec@1 18.7500 (18.7500)
Epoch [30/110]	Batch [10/120]	Loss 3.2128 (3.4845)	Prec@1 32.8125 (22.8693)
Epoch [30/110]	Batch [20/120]	Loss 3.3266 (3.4465)	Prec@1 34.3750 (23.7351)
Epoch [30/110]	Batch [30/120]	Loss 3.6079 (3.4517)	Prec@1 23.4375 (23.9919)
Epoch [30/110]	Batch [40/120]	Loss 3.0525 (3.4271)	Prec@1 32.8125 (25.1905)
Epoch [30/110]	Batch [50/120]	Loss 3.6028 (3.4284)	Prec@1 20.3125 (25.0919)
Epoch [30/110]	Batch [60/120]	Loss 3.0104 (3.4218)	Prec@1 31.2500 (25.0768)
Epoch [30/110]	Batch [70/120]	Loss 3.5629 (3.4278)	Prec@1 15.6250 (24.9120)
Epoch [30/110]	Batch [80/120]	Loss 3.1682 (3.4274)	Prec@1 34.3750 (24.8843)
Epoch [30/110]	Batch [90/120]	Loss 3.4499 (3.4426)	Prec@1 28.1250 (24.6566)
Epoch [30/110]	Batch [100/120]	Loss 3.2041 (3.4182)	Prec@1 18.7500 (24.8453)
Epoch [30/110]	Batch [110/120]	Loss 3.1708 (3.3975)	Prec@1 31.2500 (25.4223)
Training Time 68.9599919319
test accuracy
Epoch [30/110]	Loss 3.7620 (4.8779)	Prec@1 25.0000 (22.0703)
Saving..
Epoch [31/110]	Batch [0/120]	Loss 3.1522 (3.1522)	Prec@1 32.8125 (32.8125)
Epoch [31/110]	Batch [10/120]	Loss 3.5818 (3.2507)	Prec@1 17.1875 (28.2670)
Epoch [31/110]	Batch [20/120]	Loss 2.7220 (3.2234)	Prec@1 40.6250 (28.6458)
Epoch [31/110]	Batch [30/120]	Loss 3.4853 (3.2615)	Prec@1 23.4375 (27.4698)
Epoch [31/110]	Batch [40/120]	Loss 3.3194 (3.2691)	Prec@1 26.5625 (27.6296)
Epoch [31/110]	Batch [50/120]	Loss 3.3760 (3.2620)	Prec@1 23.4375 (27.7880)
Epoch [31/110]	Batch [60/120]	Loss 3.2485 (3.2523)	Prec@1 23.4375 (28.0225)
Epoch [31/110]	Batch [70/120]	Loss 3.4276 (3.2642)	Prec@1 25.0000 (27.8169)
Epoch [31/110]	Batch [80/120]	Loss 2.8726 (3.2639)	Prec@1 32.8125 (27.7199)
Epoch [31/110]	Batch [90/120]	Loss 3.4226 (3.2743)	Prec@1 14.0625 (27.7644)
Epoch [31/110]	Batch [100/120]	Loss 3.4286 (3.2734)	Prec@1 29.6875 (27.6609)
Epoch [31/110]	Batch [110/120]	Loss 3.0512 (3.2640)	Prec@1 35.9375 (27.8294)
Training Time 69.7114899158
test accuracy
Epoch [31/110]	Loss 3.7459 (4.8395)	Prec@1 28.1250 (22.3438)
Saving..
Epoch [32/110]	Batch [0/120]	Loss 3.4324 (3.4324)	Prec@1 18.7500 (18.7500)
Epoch [32/110]	Batch [10/120]	Loss 3.2426 (3.2084)	Prec@1 26.5625 (29.5455)
Epoch [32/110]	Batch [20/120]	Loss 2.8142 (3.1459)	Prec@1 32.8125 (30.3571)
Epoch [32/110]	Batch [30/120]	Loss 2.7239 (3.1736)	Prec@1 37.5000 (29.4355)
Epoch [32/110]	Batch [40/120]	Loss 3.4756 (3.2049)	Prec@1 28.1250 (29.1540)
Epoch [32/110]	Batch [50/120]	Loss 3.3374 (3.2243)	Prec@1 25.0000 (28.5846)
Epoch [32/110]	Batch [60/120]	Loss 3.5092 (3.2228)	Prec@1 21.8750 (28.2531)
Epoch [32/110]	Batch [70/120]	Loss 3.2792 (3.2119)	Prec@1 29.6875 (28.1910)
Epoch [32/110]	Batch [80/120]	Loss 2.7540 (3.2154)	Prec@1 45.3125 (28.2215)
Epoch [32/110]	Batch [90/120]	Loss 3.4611 (3.2241)	Prec@1 18.7500 (27.8846)
Epoch [32/110]	Batch [100/120]	Loss 3.4923 (3.2271)	Prec@1 18.7500 (27.9239)
Epoch [32/110]	Batch [110/120]	Loss 3.3051 (3.2219)	Prec@1 21.8750 (27.8716)
Training Time 69.6949660778
test accuracy
Epoch [32/110]	Loss 3.9005 (4.8748)	Prec@1 21.8750 (22.3438)
Epoch [33/110]	Batch [0/120]	Loss 3.2743 (3.2743)	Prec@1 26.5625 (26.5625)
Epoch [33/110]	Batch [10/120]	Loss 3.2279 (3.2808)	Prec@1 23.4375 (25.7102)
Epoch [33/110]	Batch [20/120]	Loss 2.8890 (3.1570)	Prec@1 32.8125 (28.4226)
Epoch [33/110]	Batch [30/120]	Loss 3.2378 (3.1938)	Prec@1 23.4375 (28.0242)
Epoch [33/110]	Batch [40/120]	Loss 3.4407 (3.1864)	Prec@1 28.1250 (28.5823)
Epoch [33/110]	Batch [50/120]	Loss 3.3049 (3.1649)	Prec@1 29.6875 (29.1360)
Epoch [33/110]	Batch [60/120]	Loss 2.9137 (3.1506)	Prec@1 31.2500 (28.9959)
Epoch [33/110]	Batch [70/120]	Loss 3.0913 (3.1608)	Prec@1 25.0000 (28.7632)
Epoch [33/110]	Batch [80/120]	Loss 2.7554 (3.1574)	Prec@1 37.5000 (28.8387)
Epoch [33/110]	Batch [90/120]	Loss 3.8719 (3.1771)	Prec@1 15.6250 (28.6229)
Epoch [33/110]	Batch [100/120]	Loss 3.0099 (3.1782)	Prec@1 37.5000 (28.8212)
Epoch [33/110]	Batch [110/120]	Loss 3.2482 (3.1817)	Prec@1 32.8125 (28.9414)
Training Time 69.6572971344
test accuracy
Epoch [33/110]	Loss 6.2368 (6.1980)	Prec@1 25.0000 (21.8164)
Epoch [34/110]	Batch [0/120]	Loss 2.8775 (2.8775)	Prec@1 28.1250 (28.1250)
Epoch [34/110]	Batch [10/120]	Loss 3.0050 (3.1157)	Prec@1 28.1250 (29.9716)
Epoch [34/110]	Batch [20/120]	Loss 2.9891 (3.1153)	Prec@1 34.3750 (30.1339)
Epoch [34/110]	Batch [30/120]	Loss 3.2761 (3.1474)	Prec@1 26.5625 (29.5363)
Epoch [34/110]	Batch [40/120]	Loss 3.0896 (3.1602)	Prec@1 31.2500 (28.9253)
Epoch [34/110]	Batch [50/120]	Loss 3.5562 (3.1397)	Prec@1 23.4375 (29.7181)
Epoch [34/110]	Batch [60/120]	Loss 3.2829 (3.1419)	Prec@1 21.8750 (29.3033)
Epoch [34/110]	Batch [70/120]	Loss 3.0379 (3.1432)	Prec@1 32.8125 (29.3134)
Epoch [34/110]	Batch [80/120]	Loss 3.3574 (3.1456)	Prec@1 25.0000 (29.2245)
Epoch [34/110]	Batch [90/120]	Loss 2.8890 (3.1446)	Prec@1 32.8125 (29.1380)
Epoch [34/110]	Batch [100/120]	Loss 2.7730 (3.1467)	Prec@1 39.0625 (29.3472)
Epoch [34/110]	Batch [110/120]	Loss 3.1204 (3.1457)	Prec@1 29.6875 (29.4200)
Training Time 69.6756269932
test accuracy
Epoch [34/110]	Loss 3.2507 (5.6597)	Prec@1 34.3750 (22.3633)
Saving..
Epoch [35/110]	Batch [0/120]	Loss 3.0662 (3.0662)	Prec@1 31.2500 (31.2500)
Epoch [35/110]	Batch [10/120]	Loss 3.1184 (3.1457)	Prec@1 34.3750 (29.8295)
Epoch [35/110]	Batch [20/120]	Loss 2.9370 (3.1368)	Prec@1 32.8125 (30.4315)
Epoch [35/110]	Batch [30/120]	Loss 2.7301 (3.1483)	Prec@1 31.2500 (29.8387)
Epoch [35/110]	Batch [40/120]	Loss 3.2487 (3.1687)	Prec@1 32.8125 (29.2302)
Epoch [35/110]	Batch [50/120]	Loss 3.4046 (3.1767)	Prec@1 17.1875 (28.7377)
Epoch [35/110]	Batch [60/120]	Loss 3.1394 (3.1778)	Prec@1 25.0000 (28.6629)
Epoch [35/110]	Batch [70/120]	Loss 3.4000 (3.1946)	Prec@1 18.7500 (28.2790)
Epoch [35/110]	Batch [80/120]	Loss 3.3908 (3.1830)	Prec@1 31.2500 (28.2215)
Epoch [35/110]	Batch [90/120]	Loss 3.4607 (3.1763)	Prec@1 23.4375 (28.1250)
Epoch [35/110]	Batch [100/120]	Loss 2.8329 (3.1706)	Prec@1 31.2500 (28.4344)
Epoch [35/110]	Batch [110/120]	Loss 2.7615 (3.1582)	Prec@1 39.0625 (28.8148)
Training Time 68.7679450512
test accuracy
Epoch [35/110]	Loss 4.2508 (5.1277)	Prec@1 9.3750 (22.4805)
Saving..
Epoch [36/110]	Batch [0/120]	Loss 3.1404 (3.1404)	Prec@1 23.4375 (23.4375)
Epoch [36/110]	Batch [10/120]	Loss 3.1911 (3.0326)	Prec@1 29.6875 (30.5398)
Epoch [36/110]	Batch [20/120]	Loss 3.6628 (3.0640)	Prec@1 21.8750 (30.8780)
Epoch [36/110]	Batch [30/120]	Loss 3.5064 (3.0934)	Prec@1 28.1250 (30.7460)
Epoch [36/110]	Batch [40/120]	Loss 3.1819 (3.0918)	Prec@1 28.1250 (30.8308)
Epoch [36/110]	Batch [50/120]	Loss 2.8953 (3.0991)	Prec@1 37.5000 (30.2696)
Epoch [36/110]	Batch [60/120]	Loss 2.9287 (3.1184)	Prec@1 32.8125 (30.0973)
Epoch [36/110]	Batch [70/120]	Loss 3.1211 (3.1148)	Prec@1 29.6875 (30.2157)
Epoch [36/110]	Batch [80/120]	Loss 3.3438 (3.1146)	Prec@1 25.0000 (30.3241)
Epoch [36/110]	Batch [90/120]	Loss 2.7762 (3.1172)	Prec@1 34.3750 (30.2370)
Epoch [36/110]	Batch [100/120]	Loss 3.0328 (3.1156)	Prec@1 34.3750 (30.3837)
Epoch [36/110]	Batch [110/120]	Loss 3.6602 (3.1351)	Prec@1 20.3125 (29.8564)
Training Time 68.5989780426
test accuracy
Epoch [36/110]	Loss 3.6343 (6.4667)	Prec@1 28.1250 (22.3438)
Epoch [37/110]	Batch [0/120]	Loss 2.9868 (2.9868)	Prec@1 35.9375 (35.9375)
Epoch [37/110]	Batch [10/120]	Loss 3.4661 (3.0276)	Prec@1 23.4375 (31.1080)
Epoch [37/110]	Batch [20/120]	Loss 3.1271 (3.0012)	Prec@1 26.5625 (30.9524)
Epoch [37/110]	Batch [30/120]	Loss 2.7950 (3.0107)	Prec@1 35.9375 (31.3508)
Epoch [37/110]	Batch [40/120]	Loss 3.1555 (3.0465)	Prec@1 28.1250 (30.6402)
Epoch [37/110]	Batch [50/120]	Loss 3.3800 (3.0468)	Prec@1 28.1250 (30.9130)
Epoch [37/110]	Batch [60/120]	Loss 3.1582 (3.0672)	Prec@1 28.1250 (30.4303)
Epoch [37/110]	Batch [70/120]	Loss 3.2291 (3.0755)	Prec@1 29.6875 (29.9516)
Epoch [37/110]	Batch [80/120]	Loss 2.9567 (3.0617)	Prec@1 28.1250 (30.1698)
Epoch [37/110]	Batch [90/120]	Loss 3.2456 (3.0712)	Prec@1 26.5625 (29.9107)
Epoch [37/110]	Batch [100/120]	Loss 3.3195 (3.0758)	Prec@1 29.6875 (29.7958)
Epoch [37/110]	Batch [110/120]	Loss 3.0742 (3.0781)	Prec@1 29.6875 (29.7860)
Training Time 69.1794710159
test accuracy
Epoch [37/110]	Loss 6.8479 (5.1272)	Prec@1 15.6250 (22.5977)
Saving..
Epoch [38/110]	Batch [0/120]	Loss 3.0874 (3.0874)	Prec@1 25.0000 (25.0000)
Epoch [38/110]	Batch [10/120]	Loss 3.2004 (3.0627)	Prec@1 35.9375 (32.9545)
Epoch [38/110]	Batch [20/120]	Loss 3.1381 (2.9832)	Prec@1 31.2500 (34.2262)
Epoch [38/110]	Batch [30/120]	Loss 3.2593 (3.0402)	Prec@1 25.0000 (32.0565)
Epoch [38/110]	Batch [40/120]	Loss 3.1189 (3.0412)	Prec@1 31.2500 (31.7454)
Epoch [38/110]	Batch [50/120]	Loss 2.8664 (3.0564)	Prec@1 42.1875 (31.5564)
Epoch [38/110]	Batch [60/120]	Loss 3.0480 (3.0533)	Prec@1 31.2500 (31.5061)
Epoch [38/110]	Batch [70/120]	Loss 3.2820 (3.0732)	Prec@1 21.8750 (31.0299)
Epoch [38/110]	Batch [80/120]	Loss 2.9443 (3.0794)	Prec@1 31.2500 (30.8449)
Epoch [38/110]	Batch [90/120]	Loss 2.9733 (3.0771)	Prec@1 29.6875 (30.6147)
Epoch [38/110]	Batch [100/120]	Loss 2.8483 (3.0734)	Prec@1 32.8125 (30.8014)
Epoch [38/110]	Batch [110/120]	Loss 3.0096 (3.0721)	Prec@1 29.6875 (30.8277)
Training Time 69.468421936
test accuracy
Epoch [38/110]	Loss 6.3683 (6.0437)	Prec@1 15.6250 (22.4609)
Epoch [39/110]	Batch [0/120]	Loss 2.8861 (2.8861)	Prec@1 37.5000 (37.5000)
Epoch [39/110]	Batch [10/120]	Loss 3.1071 (2.9866)	Prec@1 31.2500 (32.3864)
Epoch [39/110]	Batch [20/120]	Loss 3.0517 (3.0099)	Prec@1 26.5625 (31.7708)
Epoch [39/110]	Batch [30/120]	Loss 3.1727 (2.9985)	Prec@1 28.1250 (31.6532)
Epoch [39/110]	Batch [40/120]	Loss 3.2733 (3.0208)	Prec@1 26.5625 (31.9741)
Epoch [39/110]	Batch [50/120]	Loss 3.1775 (3.0061)	Prec@1 29.6875 (32.5674)
Epoch [39/110]	Batch [60/120]	Loss 3.0108 (3.0344)	Prec@1 29.6875 (31.7367)
Epoch [39/110]	Batch [70/120]	Loss 2.9794 (3.0397)	Prec@1 26.5625 (31.1180)
Epoch [39/110]	Batch [80/120]	Loss 3.3774 (3.0451)	Prec@1 28.1250 (30.8642)
Epoch [39/110]	Batch [90/120]	Loss 2.9982 (3.0575)	Prec@1 29.6875 (30.7521)
Epoch [39/110]	Batch [100/120]	Loss 2.9217 (3.0564)	Prec@1 29.6875 (30.7550)
Epoch [39/110]	Batch [110/120]	Loss 2.9750 (3.0551)	Prec@1 29.6875 (30.7573)
Training Time 70.231361866
test accuracy
Epoch [39/110]	Loss 4.1998 (7.1695)	Prec@1 15.6250 (22.8906)
Saving..
Epoch [40/110]	Batch [0/120]	Loss 3.4425 (3.4425)	Prec@1 26.5625 (26.5625)
Epoch [40/110]	Batch [10/120]	Loss 3.2117 (3.0805)	Prec@1 28.1250 (28.8352)
Epoch [40/110]	Batch [20/120]	Loss 3.0983 (3.0012)	Prec@1 39.0625 (31.7708)
Epoch [40/110]	Batch [30/120]	Loss 3.2229 (3.0244)	Prec@1 31.2500 (30.9476)
Epoch [40/110]	Batch [40/120]	Loss 3.1385 (3.0091)	Prec@1 28.1250 (31.7073)
Epoch [40/110]	Batch [50/120]	Loss 2.9572 (2.9927)	Prec@1 34.3750 (32.2304)
Epoch [40/110]	Batch [60/120]	Loss 2.7483 (3.0058)	Prec@1 29.6875 (32.0441)
Epoch [40/110]	Batch [70/120]	Loss 2.7871 (3.0182)	Prec@1 35.9375 (31.8002)
Epoch [40/110]	Batch [80/120]	Loss 3.0430 (3.0269)	Prec@1 37.5000 (31.4043)
Epoch [40/110]	Batch [90/120]	Loss 3.2681 (3.0299)	Prec@1 29.6875 (31.4045)
Epoch [40/110]	Batch [100/120]	Loss 3.0483 (3.0364)	Prec@1 29.6875 (31.3583)
Epoch [40/110]	Batch [110/120]	Loss 2.8351 (3.0384)	Prec@1 39.0625 (31.4048)
Training Time 70.1958479881
test accuracy
Epoch [40/110]	Loss 6.8200 (5.6444)	Prec@1 29.6875 (22.9492)
Saving..
Epoch [41/110]	Batch [0/120]	Loss 3.3198 (3.3198)	Prec@1 23.4375 (23.4375)
Epoch [41/110]	Batch [10/120]	Loss 2.9144 (2.9797)	Prec@1 29.6875 (30.1136)
Epoch [41/110]	Batch [20/120]	Loss 2.9320 (3.0154)	Prec@1 25.0000 (30.3571)
Epoch [41/110]	Batch [30/120]	Loss 2.8926 (3.0135)	Prec@1 35.9375 (30.7964)
Epoch [41/110]	Batch [40/120]	Loss 2.8664 (3.0072)	Prec@1 32.8125 (30.6402)
Epoch [41/110]	Batch [50/120]	Loss 3.1549 (3.0149)	Prec@1 23.4375 (30.6066)
Epoch [41/110]	Batch [60/120]	Loss 2.6106 (3.0207)	Prec@1 32.8125 (30.1230)
Epoch [41/110]	Batch [70/120]	Loss 3.0691 (3.0168)	Prec@1 21.8750 (30.5238)
Epoch [41/110]	Batch [80/120]	Loss 3.1544 (3.0122)	Prec@1 31.2500 (30.8063)
Epoch [41/110]	Batch [90/120]	Loss 3.1096 (3.0195)	Prec@1 28.1250 (30.8207)
Epoch [41/110]	Batch [100/120]	Loss 3.2461 (3.0303)	Prec@1 25.0000 (30.6776)
Epoch [41/110]	Batch [110/120]	Loss 3.6626 (3.0360)	Prec@1 20.3125 (30.6025)
Training Time 71.2140710354
test accuracy
Epoch [41/110]	Loss 3.9457 (4.3002)	Prec@1 20.3125 (23.1641)
Saving..
Epoch [42/110]	Batch [0/120]	Loss 2.8865 (2.8865)	Prec@1 37.5000 (37.5000)
Epoch [42/110]	Batch [10/120]	Loss 3.0062 (2.9137)	Prec@1 40.6250 (35.6534)
Epoch [42/110]	Batch [20/120]	Loss 2.8600 (2.9030)	Prec@1 35.9375 (34.1518)
Epoch [42/110]	Batch [30/120]	Loss 3.1108 (2.9571)	Prec@1 28.1250 (32.6613)
Epoch [42/110]	Batch [40/120]	Loss 3.0051 (2.9677)	Prec@1 31.2500 (32.2790)
Epoch [42/110]	Batch [50/120]	Loss 3.0516 (2.9827)	Prec@1 26.5625 (31.6483)
Epoch [42/110]	Batch [60/120]	Loss 2.6440 (2.9699)	Prec@1 39.0625 (32.1465)
Epoch [42/110]	Batch [70/120]	Loss 2.6861 (2.9710)	Prec@1 34.3750 (32.0202)
Epoch [42/110]	Batch [80/120]	Loss 3.2868 (2.9863)	Prec@1 23.4375 (31.7515)
Epoch [42/110]	Batch [90/120]	Loss 2.7251 (2.9867)	Prec@1 39.0625 (31.6106)
Epoch [42/110]	Batch [100/120]	Loss 3.2368 (2.9954)	Prec@1 31.2500 (31.4047)
Epoch [42/110]	Batch [110/120]	Loss 2.9425 (3.0022)	Prec@1 23.4375 (31.1655)
Training Time 69.8723189831
test accuracy
Epoch [42/110]	Loss 3.6468 (5.8376)	Prec@1 23.4375 (22.9102)
Epoch [43/110]	Batch [0/120]	Loss 2.9558 (2.9558)	Prec@1 39.0625 (39.0625)
Epoch [43/110]	Batch [10/120]	Loss 2.8469 (2.8514)	Prec@1 32.8125 (34.8011)
Epoch [43/110]	Batch [20/120]	Loss 2.8959 (2.8739)	Prec@1 28.1250 (34.1518)
Epoch [43/110]	Batch [30/120]	Loss 2.6023 (2.8996)	Prec@1 43.7500 (34.2742)
Epoch [43/110]	Batch [40/120]	Loss 3.1875 (2.9069)	Prec@1 23.4375 (33.9177)
Epoch [43/110]	Batch [50/120]	Loss 2.9223 (2.9077)	Prec@1 35.9375 (34.0993)
Epoch [43/110]	Batch [60/120]	Loss 3.0830 (2.9034)	Prec@1 26.5625 (34.1957)
Epoch [43/110]	Batch [70/120]	Loss 2.7479 (2.9199)	Prec@1 31.2500 (33.5827)
Epoch [43/110]	Batch [80/120]	Loss 2.9990 (2.9469)	Prec@1 37.5000 (33.1983)
Epoch [43/110]	Batch [90/120]	Loss 3.0386 (2.9528)	Prec@1 34.3750 (33.0872)
Epoch [43/110]	Batch [100/120]	Loss 3.2270 (2.9525)	Prec@1 26.5625 (32.9981)
Epoch [43/110]	Batch [110/120]	Loss 3.3010 (2.9678)	Prec@1 23.4375 (32.7280)
Training Time 69.6964690685
test accuracy
Epoch [43/110]	Loss 4.7157 (4.9098)	Prec@1 18.7500 (23.6328)
Saving..
Epoch [44/110]	Batch [0/120]	Loss 3.1153 (3.1153)	Prec@1 34.3750 (34.3750)
Epoch [44/110]	Batch [10/120]	Loss 3.0632 (2.8712)	Prec@1 26.5625 (33.8068)
Epoch [44/110]	Batch [20/120]	Loss 2.7855 (2.9135)	Prec@1 37.5000 (32.8869)
Epoch [44/110]	Batch [30/120]	Loss 2.8867 (2.9400)	Prec@1 35.9375 (32.4093)
Epoch [44/110]	Batch [40/120]	Loss 3.0130 (2.9469)	Prec@1 28.1250 (32.2409)
Epoch [44/110]	Batch [50/120]	Loss 3.0675 (2.9756)	Prec@1 31.2500 (31.7402)
Epoch [44/110]	Batch [60/120]	Loss 3.0366 (2.9927)	Prec@1 25.0000 (31.4293)
Epoch [44/110]	Batch [70/120]	Loss 2.6211 (2.9779)	Prec@1 40.6250 (31.5581)
Epoch [44/110]	Batch [80/120]	Loss 2.9398 (2.9938)	Prec@1 34.3750 (31.3465)
Epoch [44/110]	Batch [90/120]	Loss 3.0564 (2.9845)	Prec@1 34.3750 (31.7823)
Epoch [44/110]	Batch [100/120]	Loss 3.6372 (2.9919)	Prec@1 25.0000 (31.8379)
Epoch [44/110]	Batch [110/120]	Loss 3.0410 (2.9915)	Prec@1 35.9375 (32.0383)
Training Time 69.0879220963
test accuracy
Epoch [44/110]	Loss 4.1670 (5.8120)	Prec@1 14.0625 (23.3203)
Epoch [45/110]	Batch [0/120]	Loss 3.0288 (3.0288)	Prec@1 28.1250 (28.1250)
Epoch [45/110]	Batch [10/120]	Loss 2.8195 (2.9880)	Prec@1 28.1250 (31.8182)
Epoch [45/110]	Batch [20/120]	Loss 2.9871 (2.9182)	Prec@1 31.2500 (33.1845)
Epoch [45/110]	Batch [30/120]	Loss 2.8279 (2.9160)	Prec@1 34.3750 (33.8206)
Epoch [45/110]	Batch [40/120]	Loss 3.3875 (2.9334)	Prec@1 23.4375 (33.3079)
Epoch [45/110]	Batch [50/120]	Loss 2.9146 (2.9262)	Prec@1 21.8750 (33.4252)
Epoch [45/110]	Batch [60/120]	Loss 3.1293 (2.9207)	Prec@1 29.6875 (33.3248)
Epoch [45/110]	Batch [70/120]	Loss 3.3336 (2.9389)	Prec@1 31.2500 (33.0546)
Epoch [45/110]	Batch [80/120]	Loss 2.6236 (2.9436)	Prec@1 40.6250 (32.8318)
Epoch [45/110]	Batch [90/120]	Loss 3.1572 (2.9453)	Prec@1 26.5625 (32.8812)
Epoch [45/110]	Batch [100/120]	Loss 2.7892 (2.9430)	Prec@1 35.9375 (32.7661)
Epoch [45/110]	Batch [110/120]	Loss 2.9394 (2.9444)	Prec@1 32.8125 (32.6717)
Training Time 69.7340419292
test accuracy
Epoch [45/110]	Loss 10.4367 (6.3249)	Prec@1 20.3125 (22.7734)
Epoch [46/110]	Batch [0/120]	Loss 3.1566 (3.1566)	Prec@1 23.4375 (23.4375)
Epoch [46/110]	Batch [10/120]	Loss 3.2159 (2.9117)	Prec@1 29.6875 (32.9545)
Epoch [46/110]	Batch [20/120]	Loss 2.6175 (2.9178)	Prec@1 37.5000 (32.8869)
Epoch [46/110]	Batch [30/120]	Loss 2.7555 (2.8843)	Prec@1 42.1875 (33.9718)
Epoch [46/110]	Batch [40/120]	Loss 2.8856 (2.9218)	Prec@1 31.2500 (33.2317)
Epoch [46/110]	Batch [50/120]	Loss 2.9391 (2.9234)	Prec@1 37.5000 (32.9657)
Epoch [46/110]	Batch [60/120]	Loss 3.0118 (2.9206)	Prec@1 40.6250 (33.5041)
Epoch [46/110]	Batch [70/120]	Loss 2.8222 (2.9255)	Prec@1 34.3750 (33.5167)
Epoch [46/110]	Batch [80/120]	Loss 2.8026 (2.9315)	Prec@1 37.5000 (32.8704)
Epoch [46/110]	Batch [90/120]	Loss 2.8456 (2.9356)	Prec@1 37.5000 (32.8468)
Epoch [46/110]	Batch [100/120]	Loss 3.1155 (2.9397)	Prec@1 26.5625 (32.7970)
Epoch [46/110]	Batch [110/120]	Loss 3.4623 (2.9379)	Prec@1 23.4375 (33.1363)
Training Time 69.8661859035
test accuracy
Epoch [46/110]	Loss 13.9823 (7.8194)	Prec@1 21.8750 (22.9297)
Epoch [47/110]	Batch [0/120]	Loss 2.7321 (2.7321)	Prec@1 37.5000 (37.5000)
Epoch [47/110]	Batch [10/120]	Loss 2.7831 (2.7479)	Prec@1 45.3125 (38.6364)
Epoch [47/110]	Batch [20/120]	Loss 2.8793 (2.7985)	Prec@1 31.2500 (36.5327)
Epoch [47/110]	Batch [30/120]	Loss 3.2837 (2.8347)	Prec@1 23.4375 (35.7359)
Epoch [47/110]	Batch [40/120]	Loss 2.6802 (2.8416)	Prec@1 39.0625 (35.2896)
Epoch [47/110]	Batch [50/120]	Loss 3.1565 (2.8653)	Prec@1 25.0000 (34.6814)
Epoch [47/110]	Batch [60/120]	Loss 3.1756 (2.8742)	Prec@1 28.1250 (34.1189)
Epoch [47/110]	Batch [70/120]	Loss 2.7583 (2.8790)	Prec@1 42.1875 (34.4850)
Epoch [47/110]	Batch [80/120]	Loss 2.9716 (2.8880)	Prec@1 31.2500 (34.2978)
Epoch [47/110]	Batch [90/120]	Loss 3.0404 (2.8751)	Prec@1 31.2500 (34.5124)
Epoch [47/110]	Batch [100/120]	Loss 3.0362 (2.8872)	Prec@1 31.2500 (34.1275)
Epoch [47/110]	Batch [110/120]	Loss 3.0228 (2.8939)	Prec@1 34.3750 (34.0090)
Training Time 70.9235711098
test accuracy
Epoch [47/110]	Loss 9.2644 (5.3393)	Prec@1 28.1250 (23.6328)
Epoch [48/110]	Batch [0/120]	Loss 2.6067 (2.6067)	Prec@1 40.6250 (40.6250)
Epoch [48/110]	Batch [10/120]	Loss 2.6766 (2.8785)	Prec@1 34.3750 (34.9432)
Epoch [48/110]	Batch [20/120]	Loss 2.7707 (2.8821)	Prec@1 37.5000 (33.5565)
Epoch [48/110]	Batch [30/120]	Loss 2.9786 (2.9176)	Prec@1 32.8125 (33.2157)
Epoch [48/110]	Batch [40/120]	Loss 2.8755 (2.8908)	Prec@1 35.9375 (33.7652)
Epoch [48/110]	Batch [50/120]	Loss 3.1517 (2.8757)	Prec@1 28.1250 (34.1299)
Epoch [48/110]	Batch [60/120]	Loss 2.7227 (2.8798)	Prec@1 37.5000 (33.9139)
Epoch [48/110]	Batch [70/120]	Loss 2.9648 (2.8998)	Prec@1 32.8125 (33.7368)
Epoch [48/110]	Batch [80/120]	Loss 2.8464 (2.8955)	Prec@1 40.6250 (34.0856)
Epoch [48/110]	Batch [90/120]	Loss 3.1267 (2.8880)	Prec@1 32.8125 (34.1346)
Epoch [48/110]	Batch [100/120]	Loss 2.5497 (2.8969)	Prec@1 39.0625 (33.8645)
Epoch [48/110]	Batch [110/120]	Loss 2.7753 (2.9027)	Prec@1 37.5000 (33.7838)
Training Time 70.2266759872
test accuracy
Epoch [48/110]	Loss 3.8082 (5.0383)	Prec@1 23.4375 (23.5352)
Epoch [49/110]	Batch [0/120]	Loss 2.5678 (2.5678)	Prec@1 42.1875 (42.1875)
Epoch [49/110]	Batch [10/120]	Loss 3.3356 (2.7836)	Prec@1 21.8750 (38.7784)
Epoch [49/110]	Batch [20/120]	Loss 2.6139 (2.8675)	Prec@1 37.5000 (37.4256)
Epoch [49/110]	Batch [30/120]	Loss 2.9147 (2.8982)	Prec@1 35.9375 (36.0887)
Epoch [49/110]	Batch [40/120]	Loss 2.7597 (2.9127)	Prec@1 37.5000 (35.0610)
Epoch [49/110]	Batch [50/120]	Loss 3.0420 (2.9193)	Prec@1 31.2500 (34.5895)
Epoch [49/110]	Batch [60/120]	Loss 2.7415 (2.9195)	Prec@1 32.8125 (34.5799)
Epoch [49/110]	Batch [70/120]	Loss 2.6986 (2.9022)	Prec@1 34.3750 (34.7711)
Epoch [49/110]	Batch [80/120]	Loss 2.9489 (2.9095)	Prec@1 37.5000 (34.4329)
Epoch [49/110]	Batch [90/120]	Loss 3.0121 (2.9081)	Prec@1 29.6875 (34.1003)
Epoch [49/110]	Batch [100/120]	Loss 2.4578 (2.9048)	Prec@1 43.7500 (34.2358)
Epoch [49/110]	Batch [110/120]	Loss 2.8741 (2.8994)	Prec@1 35.9375 (34.3046)
Training Time 70.035269022
test accuracy
Epoch [49/110]	Loss 4.7556 (5.6448)	Prec@1 25.0000 (24.1016)
Saving..
Epoch [50/110]	Batch [0/120]	Loss 2.4664 (2.4664)	Prec@1 45.3125 (45.3125)
Epoch [50/110]	Batch [10/120]	Loss 2.7965 (2.8406)	Prec@1 31.2500 (35.2273)
Epoch [50/110]	Batch [20/120]	Loss 2.7709 (2.8522)	Prec@1 35.9375 (35.4911)
Epoch [50/110]	Batch [30/120]	Loss 3.2667 (2.8845)	Prec@1 20.3125 (34.3246)
Epoch [50/110]	Batch [40/120]	Loss 2.9960 (2.8839)	Prec@1 35.9375 (34.2226)
Epoch [50/110]	Batch [50/120]	Loss 2.7107 (2.8696)	Prec@1 35.9375 (34.4975)
Epoch [50/110]	Batch [60/120]	Loss 2.7418 (2.8790)	Prec@1 40.6250 (34.4006)
Epoch [50/110]	Batch [70/120]	Loss 2.9963 (2.8753)	Prec@1 34.3750 (34.7271)
Epoch [50/110]	Batch [80/120]	Loss 2.9407 (2.8870)	Prec@1 34.3750 (34.3171)
Epoch [50/110]	Batch [90/120]	Loss 2.4953 (2.8733)	Prec@1 42.1875 (34.5467)
Epoch [50/110]	Batch [100/120]	Loss 2.7718 (2.8742)	Prec@1 34.3750 (34.4524)
Epoch [50/110]	Batch [110/120]	Loss 3.0321 (2.8700)	Prec@1 26.5625 (34.3328)
Training Time 70.2286920547
test accuracy
Epoch [50/110]	Loss 3.1212 (4.5070)	Prec@1 35.9375 (23.7500)
Epoch [51/110]	Batch [0/120]	Loss 2.6909 (2.6909)	Prec@1 39.0625 (39.0625)
Epoch [51/110]	Batch [10/120]	Loss 2.7326 (2.7906)	Prec@1 35.9375 (35.6534)
Epoch [51/110]	Batch [20/120]	Loss 3.0702 (2.8247)	Prec@1 25.0000 (34.5982)
Epoch [51/110]	Batch [30/120]	Loss 2.5819 (2.8454)	Prec@1 42.1875 (34.3246)
Epoch [51/110]	Batch [40/120]	Loss 2.8875 (2.8327)	Prec@1 31.2500 (34.6418)
Epoch [51/110]	Batch [50/120]	Loss 2.9428 (2.8269)	Prec@1 29.6875 (34.6814)
Epoch [51/110]	Batch [60/120]	Loss 2.7908 (2.8250)	Prec@1 37.5000 (34.9898)
Epoch [51/110]	Batch [70/120]	Loss 3.4029 (2.8406)	Prec@1 18.7500 (34.8151)
Epoch [51/110]	Batch [80/120]	Loss 2.9055 (2.8338)	Prec@1 42.1875 (35.0502)
Epoch [51/110]	Batch [90/120]	Loss 2.7129 (2.8332)	Prec@1 37.5000 (34.9931)
Epoch [51/110]	Batch [100/120]	Loss 2.5613 (2.8336)	Prec@1 40.6250 (35.1640)
Epoch [51/110]	Batch [110/120]	Loss 2.9454 (2.8410)	Prec@1 34.3750 (35.0648)
Training Time 69.4984138012
test accuracy
Epoch [51/110]	Loss 3.9246 (7.4321)	Prec@1 25.0000 (23.1641)
Epoch [52/110]	Batch [0/120]	Loss 3.1729 (3.1729)	Prec@1 31.2500 (31.2500)
Epoch [52/110]	Batch [10/120]	Loss 2.7185 (2.7796)	Prec@1 40.6250 (36.9318)
Epoch [52/110]	Batch [20/120]	Loss 2.8132 (2.8183)	Prec@1 32.8125 (36.0863)
Epoch [52/110]	Batch [30/120]	Loss 2.6107 (2.7523)	Prec@1 37.5000 (36.7440)
Epoch [52/110]	Batch [40/120]	Loss 2.4495 (2.7507)	Prec@1 43.7500 (36.5854)
Epoch [52/110]	Batch [50/120]	Loss 2.6930 (2.7782)	Prec@1 42.1875 (36.1520)
Epoch [52/110]	Batch [60/120]	Loss 3.0951 (2.8197)	Prec@1 29.6875 (35.0666)
Epoch [52/110]	Batch [70/120]	Loss 3.0800 (2.8072)	Prec@1 26.5625 (35.3873)
Epoch [52/110]	Batch [80/120]	Loss 3.0030 (2.8211)	Prec@1 37.5000 (35.2238)
Epoch [52/110]	Batch [90/120]	Loss 2.7069 (2.8209)	Prec@1 32.8125 (35.0275)
Epoch [52/110]	Batch [100/120]	Loss 2.7705 (2.8269)	Prec@1 35.9375 (34.9319)
Epoch [52/110]	Batch [110/120]	Loss 2.5637 (2.8347)	Prec@1 34.3750 (34.6565)
Training Time 68.3906931877
test accuracy
Epoch [52/110]	Loss 4.1071 (5.4314)	Prec@1 25.0000 (23.6523)
Epoch [53/110]	Batch [0/120]	Loss 2.4242 (2.4242)	Prec@1 42.1875 (42.1875)
Epoch [53/110]	Batch [10/120]	Loss 2.2840 (2.6602)	Prec@1 45.3125 (36.5057)
Epoch [53/110]	Batch [20/120]	Loss 2.9545 (2.7316)	Prec@1 29.6875 (36.0863)
Epoch [53/110]	Batch [30/120]	Loss 2.9893 (2.7371)	Prec@1 31.2500 (36.3407)
Epoch [53/110]	Batch [40/120]	Loss 2.9226 (2.7614)	Prec@1 37.5000 (35.8613)
Epoch [53/110]	Batch [50/120]	Loss 2.9708 (2.7650)	Prec@1 29.6875 (35.6311)
Epoch [53/110]	Batch [60/120]	Loss 2.5105 (2.7580)	Prec@1 40.6250 (35.7582)
Epoch [53/110]	Batch [70/120]	Loss 2.9629 (2.7631)	Prec@1 31.2500 (35.5634)
Epoch [53/110]	Batch [80/120]	Loss 3.0100 (2.7793)	Prec@1 29.6875 (35.1080)
Epoch [53/110]	Batch [90/120]	Loss 3.2072 (2.7700)	Prec@1 28.1250 (35.4224)
Epoch [53/110]	Batch [100/120]	Loss 2.9172 (2.7930)	Prec@1 32.8125 (35.0402)
Epoch [53/110]	Batch [110/120]	Loss 2.8203 (2.8018)	Prec@1 31.2500 (35.0084)
Training Time 70.1792199612
test accuracy
Epoch [53/110]	Loss 4.1302 (5.0393)	Prec@1 20.3125 (23.9648)
Epoch [54/110]	Batch [0/120]	Loss 2.5801 (2.5801)	Prec@1 48.4375 (48.4375)
Epoch [54/110]	Batch [10/120]	Loss 2.7375 (2.7142)	Prec@1 42.1875 (35.9375)
Epoch [54/110]	Batch [20/120]	Loss 2.9933 (2.7583)	Prec@1 34.3750 (35.4167)
Epoch [54/110]	Batch [30/120]	Loss 2.9676 (2.7226)	Prec@1 37.5000 (36.9456)
Epoch [54/110]	Batch [40/120]	Loss 2.7826 (2.7415)	Prec@1 35.9375 (36.4329)
Epoch [54/110]	Batch [50/120]	Loss 2.6726 (2.7561)	Prec@1 32.8125 (36.0294)
Epoch [54/110]	Batch [60/120]	Loss 2.9553 (2.7874)	Prec@1 29.6875 (35.7326)
Epoch [54/110]	Batch [70/120]	Loss 2.7088 (2.7933)	Prec@1 43.7500 (35.8055)
Epoch [54/110]	Batch [80/120]	Loss 2.7318 (2.7807)	Prec@1 45.3125 (36.0918)
Epoch [54/110]	Batch [90/120]	Loss 2.9771 (2.7875)	Prec@1 25.0000 (35.8860)
Epoch [54/110]	Batch [100/120]	Loss 2.6253 (2.7816)	Prec@1 45.3125 (36.2005)
Epoch [54/110]	Batch [110/120]	Loss 2.9082 (2.7846)	Prec@1 35.9375 (35.9375)
Training Time 69.9889090061
test accuracy
Epoch [54/110]	Loss 3.6207 (5.5910)	Prec@1 23.4375 (23.2227)
Epoch [55/110]	Batch [0/120]	Loss 2.6352 (2.6352)	Prec@1 31.2500 (31.2500)
Epoch [55/110]	Batch [10/120]	Loss 2.8324 (2.8268)	Prec@1 26.5625 (34.6591)
Epoch [55/110]	Batch [20/120]	Loss 2.4398 (2.7862)	Prec@1 39.0625 (35.0446)
Epoch [55/110]	Batch [30/120]	Loss 2.4980 (2.7416)	Prec@1 48.4375 (36.4919)
Epoch [55/110]	Batch [40/120]	Loss 2.5437 (2.7417)	Prec@1 32.8125 (36.2805)
Epoch [55/110]	Batch [50/120]	Loss 2.8339 (2.7605)	Prec@1 31.2500 (35.8762)
Epoch [55/110]	Batch [60/120]	Loss 2.9493 (2.7614)	Prec@1 37.5000 (35.9375)
Epoch [55/110]	Batch [70/120]	Loss 2.9070 (2.7678)	Prec@1 32.8125 (35.5854)
Epoch [55/110]	Batch [80/120]	Loss 2.9937 (2.7555)	Prec@1 25.0000 (35.7253)
Epoch [55/110]	Batch [90/120]	Loss 2.5816 (2.7587)	Prec@1 43.7500 (35.5941)
Epoch [55/110]	Batch [100/120]	Loss 2.8379 (2.7706)	Prec@1 40.6250 (35.5972)
Epoch [55/110]	Batch [110/120]	Loss 2.8124 (2.7718)	Prec@1 43.7500 (35.6700)
Training Time 69.7967190742
test accuracy
Epoch [55/110]	Loss 6.5833 (4.8934)	Prec@1 25.0000 (24.1602)
Saving..
Epoch [56/110]	Batch [0/120]	Loss 2.0786 (2.0786)	Prec@1 46.8750 (46.8750)
Epoch [56/110]	Batch [10/120]	Loss 2.9287 (2.7326)	Prec@1 25.0000 (35.2273)
Epoch [56/110]	Batch [20/120]	Loss 2.8817 (2.7029)	Prec@1 32.8125 (36.9048)
Epoch [56/110]	Batch [30/120]	Loss 2.6257 (2.7557)	Prec@1 45.3125 (35.6855)
Epoch [56/110]	Batch [40/120]	Loss 3.0576 (2.7782)	Prec@1 25.0000 (35.2515)
Epoch [56/110]	Batch [50/120]	Loss 2.8572 (2.7979)	Prec@1 31.2500 (34.8958)
Epoch [56/110]	Batch [60/120]	Loss 2.5921 (2.7901)	Prec@1 35.9375 (35.1691)
Epoch [56/110]	Batch [70/120]	Loss 3.0730 (2.7789)	Prec@1 31.2500 (35.5854)
Epoch [56/110]	Batch [80/120]	Loss 2.9527 (2.7774)	Prec@1 32.8125 (35.6096)
Epoch [56/110]	Batch [90/120]	Loss 2.6395 (2.7768)	Prec@1 37.5000 (35.5769)
Epoch [56/110]	Batch [100/120]	Loss 2.6458 (2.7738)	Prec@1 35.9375 (35.5972)
Epoch [56/110]	Batch [110/120]	Loss 2.5213 (2.7825)	Prec@1 40.6250 (35.4870)
Training Time 69.9885489941
test accuracy
Epoch [56/110]	Loss 4.3818 (4.8687)	Prec@1 18.7500 (23.7891)
Epoch [57/110]	Batch [0/120]	Loss 2.8053 (2.8053)	Prec@1 29.6875 (29.6875)
Epoch [57/110]	Batch [10/120]	Loss 2.8456 (2.6818)	Prec@1 34.3750 (36.2216)
Epoch [57/110]	Batch [20/120]	Loss 2.7553 (2.7158)	Prec@1 42.1875 (36.6071)
Epoch [57/110]	Batch [30/120]	Loss 2.4422 (2.7457)	Prec@1 45.3125 (35.3831)
Epoch [57/110]	Batch [40/120]	Loss 2.6367 (2.7577)	Prec@1 37.5000 (36.0137)
Epoch [57/110]	Batch [50/120]	Loss 2.7653 (2.7604)	Prec@1 34.3750 (35.8762)
Epoch [57/110]	Batch [60/120]	Loss 2.6682 (2.7651)	Prec@1 40.6250 (36.3473)
Epoch [57/110]	Batch [70/120]	Loss 2.7866 (2.7459)	Prec@1 32.8125 (36.5977)
Epoch [57/110]	Batch [80/120]	Loss 2.5848 (2.7393)	Prec@1 39.0625 (36.8056)
Epoch [57/110]	Batch [90/120]	Loss 2.9590 (2.7337)	Prec@1 32.8125 (37.0192)
Epoch [57/110]	Batch [100/120]	Loss 3.0331 (2.7388)	Prec@1 39.0625 (36.8967)
Epoch [57/110]	Batch [110/120]	Loss 2.8635 (2.7432)	Prec@1 42.1875 (36.8102)
Training Time 70.2930159569
test accuracy
Epoch [57/110]	Loss 4.3280 (4.7420)	Prec@1 14.0625 (23.9844)
Epoch [58/110]	Batch [0/120]	Loss 2.6825 (2.6825)	Prec@1 42.1875 (42.1875)
Epoch [58/110]	Batch [10/120]	Loss 3.0235 (2.6364)	Prec@1 23.4375 (37.6420)
Epoch [58/110]	Batch [20/120]	Loss 2.6178 (2.5976)	Prec@1 37.5000 (38.6161)
Epoch [58/110]	Batch [30/120]	Loss 2.2554 (2.6281)	Prec@1 40.6250 (38.0040)
Epoch [58/110]	Batch [40/120]	Loss 2.4768 (2.6436)	Prec@1 46.8750 (37.5381)
Epoch [58/110]	Batch [50/120]	Loss 2.6439 (2.6644)	Prec@1 34.3750 (37.4694)
Epoch [58/110]	Batch [60/120]	Loss 2.5925 (2.6903)	Prec@1 39.0625 (36.9877)
Epoch [58/110]	Batch [70/120]	Loss 2.4242 (2.6967)	Prec@1 40.6250 (37.0158)
Epoch [58/110]	Batch [80/120]	Loss 2.5973 (2.7083)	Prec@1 39.0625 (36.9020)
Epoch [58/110]	Batch [90/120]	Loss 2.9183 (2.7226)	Prec@1 32.8125 (36.5213)
Epoch [58/110]	Batch [100/120]	Loss 2.7896 (2.7231)	Prec@1 35.9375 (36.5873)
Epoch [58/110]	Batch [110/120]	Loss 2.7155 (2.7230)	Prec@1 34.3750 (36.5569)
Training Time 69.7264661789
test accuracy
Epoch [58/110]	Loss 7.2860 (5.4891)	Prec@1 17.1875 (23.5742)
Epoch [59/110]	Batch [0/120]	Loss 2.9025 (2.9025)	Prec@1 28.1250 (28.1250)
Epoch [59/110]	Batch [10/120]	Loss 2.6116 (2.7272)	Prec@1 43.7500 (36.7898)
Epoch [59/110]	Batch [20/120]	Loss 2.7672 (2.7103)	Prec@1 35.9375 (37.0536)
Epoch [59/110]	Batch [30/120]	Loss 2.9194 (2.7385)	Prec@1 34.3750 (36.4415)
Epoch [59/110]	Batch [40/120]	Loss 2.7651 (2.7156)	Prec@1 40.6250 (37.4238)
Epoch [59/110]	Batch [50/120]	Loss 2.6353 (2.7157)	Prec@1 43.7500 (37.7757)
Epoch [59/110]	Batch [60/120]	Loss 2.9815 (2.7226)	Prec@1 29.6875 (37.6281)
Epoch [59/110]	Batch [70/120]	Loss 2.8728 (2.7130)	Prec@1 29.6875 (38.0722)
Epoch [59/110]	Batch [80/120]	Loss 2.8231 (2.7092)	Prec@1 32.8125 (37.9244)
Epoch [59/110]	Batch [90/120]	Loss 2.8908 (2.7075)	Prec@1 34.3750 (37.5343)
Epoch [59/110]	Batch [100/120]	Loss 3.1204 (2.7046)	Prec@1 25.0000 (37.2989)
Epoch [59/110]	Batch [110/120]	Loss 2.6063 (2.6967)	Prec@1 40.6250 (37.3874)
Training Time 69.9901969433
test accuracy
Epoch [59/110]	Loss 3.6851 (5.2199)	Prec@1 23.4375 (24.1992)
Saving..
Epoch [60/110]	Batch [0/120]	Loss 2.4242 (2.4242)	Prec@1 48.4375 (48.4375)
Epoch [60/110]	Batch [10/120]	Loss 2.5328 (2.6601)	Prec@1 48.4375 (38.9205)
Epoch [60/110]	Batch [20/120]	Loss 2.9955 (2.5926)	Prec@1 35.9375 (39.9554)
Epoch [60/110]	Batch [30/120]	Loss 2.8608 (2.6030)	Prec@1 34.3750 (39.8185)
Epoch [60/110]	Batch [40/120]	Loss 2.5267 (2.5902)	Prec@1 42.1875 (39.8628)
Epoch [60/110]	Batch [50/120]	Loss 2.4842 (2.5879)	Prec@1 45.3125 (40.1348)
Epoch [60/110]	Batch [60/120]	Loss 2.4814 (2.5895)	Prec@1 42.1875 (40.2152)
Epoch [60/110]	Batch [70/120]	Loss 2.7597 (2.5886)	Prec@1 35.9375 (40.1849)
Epoch [60/110]	Batch [80/120]	Loss 2.5002 (2.5939)	Prec@1 42.1875 (40.2585)
Epoch [60/110]	Batch [90/120]	Loss 2.9225 (2.6001)	Prec@1 37.5000 (40.4190)
Epoch [60/110]	Batch [100/120]	Loss 2.7661 (2.6060)	Prec@1 35.9375 (40.2228)
Epoch [60/110]	Batch [110/120]	Loss 2.7378 (2.5980)	Prec@1 42.1875 (40.3857)
Training Time 69.5831820965
test accuracy
Epoch [60/110]	Loss 9.0177 (4.8566)	Prec@1 21.8750 (24.6680)
Saving..
Epoch [61/110]	Batch [0/120]	Loss 2.5892 (2.5892)	Prec@1 39.0625 (39.0625)
Epoch [61/110]	Batch [10/120]	Loss 2.7108 (2.5961)	Prec@1 34.3750 (40.0568)
Epoch [61/110]	Batch [20/120]	Loss 2.7682 (2.6492)	Prec@1 34.3750 (38.7649)
Epoch [61/110]	Batch [30/120]	Loss 2.3541 (2.6452)	Prec@1 48.4375 (39.4153)
Epoch [61/110]	Batch [40/120]	Loss 2.7049 (2.6171)	Prec@1 35.9375 (39.3674)
Epoch [61/110]	Batch [50/120]	Loss 3.3206 (2.6300)	Prec@1 26.5625 (39.3995)
Epoch [61/110]	Batch [60/120]	Loss 2.7810 (2.6201)	Prec@1 35.9375 (39.2162)
Epoch [61/110]	Batch [70/120]	Loss 2.9333 (2.6094)	Prec@1 34.3750 (39.4146)
Epoch [61/110]	Batch [80/120]	Loss 2.2810 (2.6038)	Prec@1 42.1875 (39.3711)
Epoch [61/110]	Batch [90/120]	Loss 3.0851 (2.6001)	Prec@1 29.6875 (39.5776)
Epoch [61/110]	Batch [100/120]	Loss 2.4495 (2.6006)	Prec@1 51.5625 (39.5575)
Epoch [61/110]	Batch [110/120]	Loss 2.7994 (2.5932)	Prec@1 29.6875 (39.7382)
Training Time 69.2405810356
test accuracy
Epoch [61/110]	Loss 3.8528 (6.3669)	Prec@1 28.1250 (24.7852)
Saving..
Epoch [62/110]	Batch [0/120]	Loss 2.8316 (2.8316)	Prec@1 42.1875 (42.1875)
Epoch [62/110]	Batch [10/120]	Loss 3.0097 (2.6149)	Prec@1 32.8125 (42.7557)
Epoch [62/110]	Batch [20/120]	Loss 3.3425 (2.6124)	Prec@1 25.0000 (42.4107)
Epoch [62/110]	Batch [30/120]	Loss 2.2876 (2.6220)	Prec@1 40.6250 (40.5746)
Epoch [62/110]	Batch [40/120]	Loss 2.6724 (2.6027)	Prec@1 34.3750 (40.6250)
Epoch [62/110]	Batch [50/120]	Loss 2.7591 (2.6138)	Prec@1 32.8125 (39.8591)
Epoch [62/110]	Batch [60/120]	Loss 2.6481 (2.6149)	Prec@1 32.8125 (39.7797)
Epoch [62/110]	Batch [70/120]	Loss 2.5963 (2.6146)	Prec@1 40.6250 (40.0528)
Epoch [62/110]	Batch [80/120]	Loss 2.8213 (2.6122)	Prec@1 32.8125 (39.9498)
Epoch [62/110]	Batch [90/120]	Loss 2.5466 (2.6118)	Prec@1 46.8750 (40.0584)
Epoch [62/110]	Batch [100/120]	Loss 2.3136 (2.6117)	Prec@1 43.7500 (40.1764)
Epoch [62/110]	Batch [110/120]	Loss 2.8203 (2.6133)	Prec@1 34.3750 (40.0056)
Training Time 69.7133061886
test accuracy
Epoch [62/110]	Loss 6.5038 (4.3374)	Prec@1 35.9375 (24.9219)
Saving..
Epoch [63/110]	Batch [0/120]	Loss 2.9087 (2.9087)	Prec@1 35.9375 (35.9375)
Epoch [63/110]	Batch [10/120]	Loss 2.7380 (2.6427)	Prec@1 43.7500 (39.0625)
Epoch [63/110]	Batch [20/120]	Loss 2.5722 (2.6066)	Prec@1 35.9375 (39.6577)
Epoch [63/110]	Batch [30/120]	Loss 2.4149 (2.5859)	Prec@1 40.6250 (40.3730)
Epoch [63/110]	Batch [40/120]	Loss 2.4336 (2.5702)	Prec@1 45.3125 (40.2439)
Epoch [63/110]	Batch [50/120]	Loss 2.3471 (2.5645)	Prec@1 46.8750 (40.3493)
Epoch [63/110]	Batch [60/120]	Loss 2.8501 (2.5647)	Prec@1 29.6875 (40.4969)
Epoch [63/110]	Batch [70/120]	Loss 2.5106 (2.5638)	Prec@1 42.1875 (40.2509)
Epoch [63/110]	Batch [80/120]	Loss 2.4545 (2.5727)	Prec@1 43.7500 (40.2392)
Epoch [63/110]	Batch [90/120]	Loss 2.2392 (2.5646)	Prec@1 46.8750 (40.5907)
Epoch [63/110]	Batch [100/120]	Loss 2.9286 (2.5699)	Prec@1 34.3750 (40.4084)
Epoch [63/110]	Batch [110/120]	Loss 2.4378 (2.5698)	Prec@1 46.8750 (40.3435)
Training Time 70.6444818974
test accuracy
Epoch [63/110]	Loss 4.1385 (5.4867)	Prec@1 23.4375 (24.8828)
Epoch [64/110]	Batch [0/120]	Loss 2.7186 (2.7186)	Prec@1 40.6250 (40.6250)
Epoch [64/110]	Batch [10/120]	Loss 2.8280 (2.5592)	Prec@1 37.5000 (42.0455)
Epoch [64/110]	Batch [20/120]	Loss 2.2427 (2.5813)	Prec@1 51.5625 (40.5506)
Epoch [64/110]	Batch [30/120]	Loss 2.5835 (2.5930)	Prec@1 42.1875 (40.6250)
Epoch [64/110]	Batch [40/120]	Loss 2.5867 (2.5707)	Prec@1 43.7500 (41.1966)
Epoch [64/110]	Batch [50/120]	Loss 2.5338 (2.5842)	Prec@1 35.9375 (40.2574)
Epoch [64/110]	Batch [60/120]	Loss 2.4821 (2.5754)	Prec@1 42.1875 (40.4969)
Epoch [64/110]	Batch [70/120]	Loss 2.7614 (2.5736)	Prec@1 40.6250 (40.4930)
Epoch [64/110]	Batch [80/120]	Loss 2.6027 (2.5734)	Prec@1 39.0625 (40.6636)
Epoch [64/110]	Batch [90/120]	Loss 2.6623 (2.5814)	Prec@1 35.9375 (40.3331)
Epoch [64/110]	Batch [100/120]	Loss 2.4990 (2.5929)	Prec@1 45.3125 (40.0217)
Epoch [64/110]	Batch [110/120]	Loss 2.3145 (2.5887)	Prec@1 54.6875 (39.9352)
Training Time 71.5202870369
test accuracy
Epoch [64/110]	Loss 9.9554 (5.2953)	Prec@1 15.6250 (25.0391)
Saving..
Epoch [65/110]	Batch [0/120]	Loss 2.2595 (2.2595)	Prec@1 43.7500 (43.7500)
Epoch [65/110]	Batch [10/120]	Loss 2.2643 (2.5692)	Prec@1 46.8750 (38.6364)
Epoch [65/110]	Batch [20/120]	Loss 2.5080 (2.5667)	Prec@1 43.7500 (41.6667)
Epoch [65/110]	Batch [30/120]	Loss 2.1996 (2.5680)	Prec@1 50.0000 (42.1371)
Epoch [65/110]	Batch [40/120]	Loss 2.1624 (2.5584)	Prec@1 45.3125 (41.5396)
Epoch [65/110]	Batch [50/120]	Loss 2.3915 (2.5451)	Prec@1 50.0000 (42.1262)
Epoch [65/110]	Batch [60/120]	Loss 2.3986 (2.5431)	Prec@1 48.4375 (42.2643)
Epoch [65/110]	Batch [70/120]	Loss 2.8041 (2.5372)	Prec@1 32.8125 (42.1435)
Epoch [65/110]	Batch [80/120]	Loss 2.1977 (2.5334)	Prec@1 43.7500 (42.1103)
Epoch [65/110]	Batch [90/120]	Loss 2.6741 (2.5421)	Prec@1 34.3750 (41.5179)
Epoch [65/110]	Batch [100/120]	Loss 2.9467 (2.5489)	Prec@1 40.6250 (41.4604)
Epoch [65/110]	Batch [110/120]	Loss 2.5956 (2.5636)	Prec@1 40.6250 (41.3711)
Training Time 70.6567430496
test accuracy
Epoch [65/110]	Loss 4.0694 (5.2420)	Prec@1 39.0625 (25.0977)
Saving..
Epoch [66/110]	Batch [0/120]	Loss 2.9431 (2.9431)	Prec@1 39.0625 (39.0625)
Epoch [66/110]	Batch [10/120]	Loss 2.5375 (2.5829)	Prec@1 40.6250 (41.3352)
Epoch [66/110]	Batch [20/120]	Loss 2.9109 (2.6010)	Prec@1 31.2500 (39.3601)
Epoch [66/110]	Batch [30/120]	Loss 2.6333 (2.6014)	Prec@1 46.8750 (39.3145)
Epoch [66/110]	Batch [40/120]	Loss 2.4395 (2.6112)	Prec@1 43.7500 (39.2912)
Epoch [66/110]	Batch [50/120]	Loss 2.6474 (2.6146)	Prec@1 34.3750 (39.1850)
Epoch [66/110]	Batch [60/120]	Loss 2.4901 (2.6166)	Prec@1 42.1875 (39.2162)
Epoch [66/110]	Batch [70/120]	Loss 2.5979 (2.6053)	Prec@1 43.7500 (39.5687)
Epoch [66/110]	Batch [80/120]	Loss 2.2841 (2.5983)	Prec@1 48.4375 (39.8920)
Epoch [66/110]	Batch [90/120]	Loss 2.1477 (2.5796)	Prec@1 50.0000 (40.0069)
Epoch [66/110]	Batch [100/120]	Loss 2.5329 (2.5747)	Prec@1 43.7500 (40.3001)
Epoch [66/110]	Batch [110/120]	Loss 2.4873 (2.5644)	Prec@1 40.6250 (40.4561)
Training Time 68.8888669014
test accuracy
Epoch [66/110]	Loss 4.0473 (4.5648)	Prec@1 31.2500 (25.0586)
Epoch [67/110]	Batch [0/120]	Loss 2.4787 (2.4787)	Prec@1 35.9375 (35.9375)
Epoch [67/110]	Batch [10/120]	Loss 2.9995 (2.6171)	Prec@1 29.6875 (39.7727)
Epoch [67/110]	Batch [20/120]	Loss 2.5643 (2.6118)	Prec@1 39.0625 (39.1369)
Epoch [67/110]	Batch [30/120]	Loss 2.7374 (2.5882)	Prec@1 39.0625 (39.4153)
Epoch [67/110]	Batch [40/120]	Loss 2.3444 (2.5298)	Prec@1 51.5625 (41.0061)
Epoch [67/110]	Batch [50/120]	Loss 2.2695 (2.5103)	Prec@1 48.4375 (41.5441)
Epoch [67/110]	Batch [60/120]	Loss 2.6139 (2.5256)	Prec@1 46.8750 (41.4447)
Epoch [67/110]	Batch [70/120]	Loss 2.2870 (2.5203)	Prec@1 51.5625 (41.5713)
Epoch [67/110]	Batch [80/120]	Loss 2.4379 (2.5108)	Prec@1 46.8750 (41.7631)
Epoch [67/110]	Batch [90/120]	Loss 2.5299 (2.5125)	Prec@1 34.3750 (41.5350)
Epoch [67/110]	Batch [100/120]	Loss 2.7366 (2.5260)	Prec@1 40.6250 (41.1819)
Epoch [67/110]	Batch [110/120]	Loss 2.4145 (2.5421)	Prec@1 35.9375 (40.9910)
Training Time 70.7651069164
test accuracy
Epoch [67/110]	Loss 3.7797 (4.9834)	Prec@1 23.4375 (24.8438)
Epoch [68/110]	Batch [0/120]	Loss 2.4538 (2.4538)	Prec@1 40.6250 (40.6250)
Epoch [68/110]	Batch [10/120]	Loss 2.2381 (2.5636)	Prec@1 46.8750 (38.6364)
Epoch [68/110]	Batch [20/120]	Loss 2.5982 (2.5039)	Prec@1 46.8750 (40.9226)
Epoch [68/110]	Batch [30/120]	Loss 2.0230 (2.4683)	Prec@1 48.4375 (41.7339)
Epoch [68/110]	Batch [40/120]	Loss 2.4008 (2.5023)	Prec@1 43.7500 (41.2729)
Epoch [68/110]	Batch [50/120]	Loss 2.7729 (2.5328)	Prec@1 29.6875 (40.5944)
Epoch [68/110]	Batch [60/120]	Loss 2.4957 (2.5427)	Prec@1 39.0625 (40.5225)
Epoch [68/110]	Batch [70/120]	Loss 2.6582 (2.5527)	Prec@1 40.6250 (40.3829)
Epoch [68/110]	Batch [80/120]	Loss 2.1857 (2.5527)	Prec@1 51.5625 (40.7022)
Epoch [68/110]	Batch [90/120]	Loss 2.4048 (2.5482)	Prec@1 45.3125 (40.8310)
Epoch [68/110]	Batch [100/120]	Loss 2.8382 (2.5680)	Prec@1 34.3750 (40.3775)
Epoch [68/110]	Batch [110/120]	Loss 2.5883 (2.5610)	Prec@1 43.7500 (40.6813)
Training Time 69.3824930191
test accuracy
Epoch [68/110]	Loss 8.2024 (5.2164)	Prec@1 23.4375 (24.7461)
Epoch [69/110]	Batch [0/120]	Loss 2.9114 (2.9114)	Prec@1 26.5625 (26.5625)
Epoch [69/110]	Batch [10/120]	Loss 2.4902 (2.6185)	Prec@1 42.1875 (39.3466)
Epoch [69/110]	Batch [20/120]	Loss 3.0390 (2.6279)	Prec@1 32.8125 (39.2113)
Epoch [69/110]	Batch [30/120]	Loss 2.2871 (2.5967)	Prec@1 43.7500 (39.8185)
Epoch [69/110]	Batch [40/120]	Loss 2.2451 (2.5600)	Prec@1 45.3125 (40.8155)
Epoch [69/110]	Batch [50/120]	Loss 2.5526 (2.5692)	Prec@1 39.0625 (40.5025)
Epoch [69/110]	Batch [60/120]	Loss 2.3196 (2.5433)	Prec@1 43.7500 (40.9836)
Epoch [69/110]	Batch [70/120]	Loss 2.5335 (2.5430)	Prec@1 43.7500 (40.7570)
Epoch [69/110]	Batch [80/120]	Loss 2.8054 (2.5412)	Prec@1 34.3750 (40.8951)
Epoch [69/110]	Batch [90/120]	Loss 2.6991 (2.5485)	Prec@1 40.6250 (40.9512)
Epoch [69/110]	Batch [100/120]	Loss 2.6620 (2.5374)	Prec@1 37.5000 (41.1665)
Epoch [69/110]	Batch [110/120]	Loss 2.6271 (2.5376)	Prec@1 37.5000 (41.1599)
Training Time 69.3414828777
test accuracy
Epoch [69/110]	Loss 7.9269 (4.6207)	Prec@1 17.1875 (25.3906)
Saving..
Epoch [70/110]	Batch [0/120]	Loss 2.6259 (2.6259)	Prec@1 34.3750 (34.3750)
Epoch [70/110]	Batch [10/120]	Loss 2.4288 (2.5904)	Prec@1 32.8125 (40.0568)
Epoch [70/110]	Batch [20/120]	Loss 2.1824 (2.5511)	Prec@1 50.0000 (39.7321)
Epoch [70/110]	Batch [30/120]	Loss 2.9392 (2.5411)	Prec@1 34.3750 (41.1290)
Epoch [70/110]	Batch [40/120]	Loss 2.3620 (2.5495)	Prec@1 43.7500 (40.7012)
Epoch [70/110]	Batch [50/120]	Loss 2.3027 (2.5547)	Prec@1 39.0625 (39.9510)
Epoch [70/110]	Batch [60/120]	Loss 2.5407 (2.5572)	Prec@1 40.6250 (40.0102)
Epoch [70/110]	Batch [70/120]	Loss 2.6421 (2.5754)	Prec@1 46.8750 (39.8548)
Epoch [70/110]	Batch [80/120]	Loss 2.5583 (2.5513)	Prec@1 42.1875 (40.5671)
Epoch [70/110]	Batch [90/120]	Loss 2.2638 (2.5530)	Prec@1 50.0000 (40.7452)
Epoch [70/110]	Batch [100/120]	Loss 2.6178 (2.5579)	Prec@1 40.6250 (40.6714)
Epoch [70/110]	Batch [110/120]	Loss 2.7103 (2.5518)	Prec@1 31.2500 (40.7798)
Training Time 70.8077168465
test accuracy
Epoch [70/110]	Loss 4.4359 (5.7033)	Prec@1 25.0000 (24.9414)
Epoch [71/110]	Batch [0/120]	Loss 2.4958 (2.4958)	Prec@1 43.7500 (43.7500)
Epoch [71/110]	Batch [10/120]	Loss 2.5314 (2.5485)	Prec@1 45.3125 (41.0511)
Epoch [71/110]	Batch [20/120]	Loss 2.6449 (2.5901)	Prec@1 42.1875 (39.6577)
Epoch [71/110]	Batch [30/120]	Loss 2.1227 (2.5785)	Prec@1 45.3125 (39.6673)
Epoch [71/110]	Batch [40/120]	Loss 2.6015 (2.5739)	Prec@1 39.0625 (39.8628)
Epoch [71/110]	Batch [50/120]	Loss 2.2830 (2.5540)	Prec@1 43.7500 (40.3493)
Epoch [71/110]	Batch [60/120]	Loss 2.8612 (2.5409)	Prec@1 28.1250 (40.2408)
Epoch [71/110]	Batch [70/120]	Loss 2.2553 (2.5375)	Prec@1 45.3125 (40.1188)
Epoch [71/110]	Batch [80/120]	Loss 2.5792 (2.5362)	Prec@1 39.0625 (40.2971)
Epoch [71/110]	Batch [90/120]	Loss 2.5482 (2.5210)	Prec@1 32.8125 (40.6078)
Epoch [71/110]	Batch [100/120]	Loss 2.8476 (2.5282)	Prec@1 35.9375 (40.5476)
Epoch [71/110]	Batch [110/120]	Loss 2.6993 (2.5282)	Prec@1 34.3750 (40.5124)
Training Time 70.5142581463
test accuracy
Epoch [71/110]	Loss 3.5738 (4.7132)	Prec@1 25.0000 (25.1953)
Epoch [72/110]	Batch [0/120]	Loss 2.7529 (2.7529)	Prec@1 29.6875 (29.6875)
Epoch [72/110]	Batch [10/120]	Loss 2.9302 (2.5565)	Prec@1 35.9375 (40.0568)
Epoch [72/110]	Batch [20/120]	Loss 2.6493 (2.5503)	Prec@1 43.7500 (40.3274)
Epoch [72/110]	Batch [30/120]	Loss 3.3345 (2.5809)	Prec@1 31.2500 (40.3226)
Epoch [72/110]	Batch [40/120]	Loss 2.8195 (2.5826)	Prec@1 37.5000 (40.6250)
Epoch [72/110]	Batch [50/120]	Loss 2.5422 (2.5667)	Prec@1 40.6250 (40.7475)
Epoch [72/110]	Batch [60/120]	Loss 2.3263 (2.5375)	Prec@1 42.1875 (41.5215)
Epoch [72/110]	Batch [70/120]	Loss 2.2717 (2.5330)	Prec@1 42.1875 (41.7254)
Epoch [72/110]	Batch [80/120]	Loss 2.6319 (2.5291)	Prec@1 37.5000 (41.8789)
Epoch [72/110]	Batch [90/120]	Loss 2.5247 (2.5338)	Prec@1 42.1875 (41.9471)
Epoch [72/110]	Batch [100/120]	Loss 2.2330 (2.5294)	Prec@1 50.0000 (41.8626)
Epoch [72/110]	Batch [110/120]	Loss 2.6712 (2.5313)	Prec@1 40.6250 (41.6385)
Training Time 70.2465949059
test accuracy
Epoch [72/110]	Loss 9.4253 (5.5492)	Prec@1 23.4375 (25.0977)
Epoch [73/110]	Batch [0/120]	Loss 2.5093 (2.5093)	Prec@1 45.3125 (45.3125)
Epoch [73/110]	Batch [10/120]	Loss 2.5438 (2.4897)	Prec@1 43.7500 (42.4716)
Epoch [73/110]	Batch [20/120]	Loss 2.8330 (2.5557)	Prec@1 40.6250 (41.7411)
Epoch [73/110]	Batch [30/120]	Loss 2.6767 (2.5594)	Prec@1 39.0625 (41.2802)
Epoch [73/110]	Batch [40/120]	Loss 2.3170 (2.5684)	Prec@1 51.5625 (41.1204)
Epoch [73/110]	Batch [50/120]	Loss 2.5759 (2.5727)	Prec@1 42.1875 (41.2071)
Epoch [73/110]	Batch [60/120]	Loss 2.8323 (2.5580)	Prec@1 39.0625 (41.3678)
Epoch [73/110]	Batch [70/120]	Loss 2.3007 (2.5437)	Prec@1 43.7500 (41.6373)
Epoch [73/110]	Batch [80/120]	Loss 2.1057 (2.5359)	Prec@1 53.1250 (41.6667)
Epoch [73/110]	Batch [90/120]	Loss 2.5971 (2.5458)	Prec@1 39.0625 (41.4835)
Epoch [73/110]	Batch [100/120]	Loss 2.5274 (2.5514)	Prec@1 43.7500 (41.4913)
Epoch [73/110]	Batch [110/120]	Loss 2.9997 (2.5490)	Prec@1 35.9375 (41.6244)
Training Time 68.7081689835
test accuracy
Epoch [73/110]	Loss 3.8110 (7.6324)	Prec@1 21.8750 (24.7461)
Epoch [74/110]	Batch [0/120]	Loss 2.7174 (2.7174)	Prec@1 43.7500 (43.7500)
Epoch [74/110]	Batch [10/120]	Loss 2.4733 (2.5506)	Prec@1 42.1875 (42.7557)
Epoch [74/110]	Batch [20/120]	Loss 2.4964 (2.5728)	Prec@1 45.3125 (40.7738)
Epoch [74/110]	Batch [30/120]	Loss 2.4121 (2.5464)	Prec@1 45.3125 (42.1875)
Epoch [74/110]	Batch [40/120]	Loss 2.6951 (2.5067)	Prec@1 40.6250 (42.8735)
Epoch [74/110]	Batch [50/120]	Loss 2.5996 (2.5320)	Prec@1 42.1875 (42.3713)
Epoch [74/110]	Batch [60/120]	Loss 2.6442 (2.5081)	Prec@1 39.0625 (43.0072)
Epoch [74/110]	Batch [70/120]	Loss 2.2951 (2.5094)	Prec@1 42.1875 (42.7157)
Epoch [74/110]	Batch [80/120]	Loss 2.5966 (2.5119)	Prec@1 43.7500 (42.5926)
Epoch [74/110]	Batch [90/120]	Loss 2.5601 (2.5081)	Prec@1 42.1875 (42.5137)
Epoch [74/110]	Batch [100/120]	Loss 2.4485 (2.5152)	Prec@1 42.1875 (42.2184)
Epoch [74/110]	Batch [110/120]	Loss 2.6700 (2.5220)	Prec@1 31.2500 (42.0327)
Training Time 69.0770170689
test accuracy
Epoch [74/110]	Loss 3.5644 (4.9161)	Prec@1 26.5625 (24.8633)
Epoch [75/110]	Batch [0/120]	Loss 2.6496 (2.6496)	Prec@1 31.2500 (31.2500)
Epoch [75/110]	Batch [10/120]	Loss 2.3946 (2.5607)	Prec@1 42.1875 (39.9148)
Epoch [75/110]	Batch [20/120]	Loss 2.4828 (2.5690)	Prec@1 37.5000 (39.8810)
Epoch [75/110]	Batch [30/120]	Loss 2.4430 (2.5902)	Prec@1 43.7500 (39.8690)
Epoch [75/110]	Batch [40/120]	Loss 2.1501 (2.5578)	Prec@1 50.0000 (40.7393)
Epoch [75/110]	Batch [50/120]	Loss 1.7828 (2.5143)	Prec@1 64.0625 (41.7892)
Epoch [75/110]	Batch [60/120]	Loss 2.9133 (2.5290)	Prec@1 32.8125 (41.5471)
Epoch [75/110]	Batch [70/120]	Loss 2.0094 (2.5190)	Prec@1 56.2500 (41.8574)
Epoch [75/110]	Batch [80/120]	Loss 2.3372 (2.5224)	Prec@1 45.3125 (41.7438)
Epoch [75/110]	Batch [90/120]	Loss 2.3267 (2.5204)	Prec@1 48.4375 (41.8441)
Epoch [75/110]	Batch [100/120]	Loss 2.6792 (2.5374)	Prec@1 39.0625 (41.4604)
Epoch [75/110]	Batch [110/120]	Loss 2.4591 (2.5380)	Prec@1 45.3125 (41.4977)
Training Time 69.5544641018
test accuracy
Epoch [75/110]	Loss 3.7365 (5.2835)	Prec@1 21.8750 (24.8047)
Epoch [76/110]	Batch [0/120]	Loss 2.7993 (2.7993)	Prec@1 35.9375 (35.9375)
Epoch [76/110]	Batch [10/120]	Loss 2.7997 (2.5437)	Prec@1 34.3750 (41.3352)
Epoch [76/110]	Batch [20/120]	Loss 2.1112 (2.4864)	Prec@1 53.1250 (41.7411)
Epoch [76/110]	Batch [30/120]	Loss 2.8928 (2.5176)	Prec@1 39.0625 (41.1794)
Epoch [76/110]	Batch [40/120]	Loss 2.3840 (2.5185)	Prec@1 46.8750 (41.4634)
Epoch [76/110]	Batch [50/120]	Loss 2.4597 (2.5372)	Prec@1 40.6250 (41.6054)
Epoch [76/110]	Batch [60/120]	Loss 2.6936 (2.5632)	Prec@1 37.5000 (40.5738)
Epoch [76/110]	Batch [70/120]	Loss 2.2942 (2.5540)	Prec@1 48.4375 (40.6250)
Epoch [76/110]	Batch [80/120]	Loss 2.4254 (2.5483)	Prec@1 32.8125 (40.7215)
Epoch [76/110]	Batch [90/120]	Loss 2.6260 (2.5375)	Prec@1 37.5000 (40.9341)
Epoch [76/110]	Batch [100/120]	Loss 2.6355 (2.5302)	Prec@1 37.5000 (41.0891)
Epoch [76/110]	Batch [110/120]	Loss 2.7200 (2.5318)	Prec@1 39.0625 (41.1599)
Training Time 68.2382349968
test accuracy
Epoch [76/110]	Loss 3.6189 (5.0821)	Prec@1 28.1250 (24.9219)
Epoch [77/110]	Batch [0/120]	Loss 2.7262 (2.7262)	Prec@1 31.2500 (31.2500)
Epoch [77/110]	Batch [10/120]	Loss 2.3238 (2.4797)	Prec@1 50.0000 (40.0568)
Epoch [77/110]	Batch [20/120]	Loss 2.2204 (2.5054)	Prec@1 43.7500 (39.4345)
Epoch [77/110]	Batch [30/120]	Loss 2.3247 (2.4854)	Prec@1 45.3125 (40.4738)
Epoch [77/110]	Batch [40/120]	Loss 1.9690 (2.4777)	Prec@1 57.8125 (41.0823)
Epoch [77/110]	Batch [50/120]	Loss 3.0649 (2.4870)	Prec@1 31.2500 (41.3603)
Epoch [77/110]	Batch [60/120]	Loss 2.1413 (2.4907)	Prec@1 53.1250 (41.0605)
Epoch [77/110]	Batch [70/120]	Loss 2.4685 (2.5132)	Prec@1 40.6250 (40.6030)
Epoch [77/110]	Batch [80/120]	Loss 2.6168 (2.5246)	Prec@1 35.9375 (40.4707)
Epoch [77/110]	Batch [90/120]	Loss 2.6596 (2.5270)	Prec@1 42.1875 (40.6765)
Epoch [77/110]	Batch [100/120]	Loss 2.1815 (2.5169)	Prec@1 46.8750 (40.8725)
Epoch [77/110]	Batch [110/120]	Loss 2.9153 (2.5260)	Prec@1 31.2500 (40.8643)
Training Time 68.5562450886
test accuracy
Epoch [77/110]	Loss 3.5147 (5.7232)	Prec@1 29.6875 (25.2539)
Epoch [78/110]	Batch [0/120]	Loss 2.2616 (2.2616)	Prec@1 35.9375 (35.9375)
Epoch [78/110]	Batch [10/120]	Loss 2.6061 (2.4495)	Prec@1 46.8750 (42.1875)
Epoch [78/110]	Batch [20/120]	Loss 2.1288 (2.5158)	Prec@1 46.8750 (40.6994)
Epoch [78/110]	Batch [30/120]	Loss 2.5469 (2.5079)	Prec@1 37.5000 (40.8770)
Epoch [78/110]	Batch [40/120]	Loss 2.7447 (2.5434)	Prec@1 34.3750 (40.5107)
Epoch [78/110]	Batch [50/120]	Loss 2.6419 (2.5534)	Prec@1 39.0625 (40.6556)
Epoch [78/110]	Batch [60/120]	Loss 2.3768 (2.5298)	Prec@1 39.0625 (41.1885)
Epoch [78/110]	Batch [70/120]	Loss 2.7193 (2.5327)	Prec@1 42.1875 (41.3292)
Epoch [78/110]	Batch [80/120]	Loss 2.0870 (2.5301)	Prec@1 46.8750 (41.4545)
Epoch [78/110]	Batch [90/120]	Loss 2.9185 (2.5425)	Prec@1 34.3750 (41.1229)
Epoch [78/110]	Batch [100/120]	Loss 2.3263 (2.5429)	Prec@1 45.3125 (41.3521)
Epoch [78/110]	Batch [110/120]	Loss 2.3438 (2.5476)	Prec@1 40.6250 (41.0614)
Training Time 69.6061251163
test accuracy
Epoch [78/110]	Loss 3.0430 (5.6105)	Prec@1 37.5000 (25.1758)
Epoch [79/110]	Batch [0/120]	Loss 2.5653 (2.5653)	Prec@1 37.5000 (37.5000)
Epoch [79/110]	Batch [10/120]	Loss 2.2827 (2.5158)	Prec@1 51.5625 (41.6193)
Epoch [79/110]	Batch [20/120]	Loss 2.3208 (2.5009)	Prec@1 43.7500 (41.2946)
Epoch [79/110]	Batch [30/120]	Loss 2.4020 (2.5327)	Prec@1 45.3125 (40.8770)
Epoch [79/110]	Batch [40/120]	Loss 2.6541 (2.5307)	Prec@1 40.6250 (40.6631)
Epoch [79/110]	Batch [50/120]	Loss 2.5802 (2.5021)	Prec@1 29.6875 (41.5748)
Epoch [79/110]	Batch [60/120]	Loss 2.2900 (2.4884)	Prec@1 46.8750 (41.7008)
Epoch [79/110]	Batch [70/120]	Loss 2.1617 (2.4719)	Prec@1 50.0000 (41.9014)
Epoch [79/110]	Batch [80/120]	Loss 2.9700 (2.4838)	Prec@1 31.2500 (41.5316)
Epoch [79/110]	Batch [90/120]	Loss 2.8714 (2.4885)	Prec@1 28.1250 (41.5694)
Epoch [79/110]	Batch [100/120]	Loss 2.5033 (2.5032)	Prec@1 39.0625 (41.4295)
Epoch [79/110]	Batch [110/120]	Loss 2.4226 (2.4967)	Prec@1 51.5625 (41.9060)
Training Time 70.7802538872
test accuracy
Epoch [79/110]	Loss 8.7649 (4.8387)	Prec@1 23.4375 (25.2930)
Epoch [80/110]	Batch [0/120]	Loss 2.3755 (2.3755)	Prec@1 46.8750 (46.8750)
Epoch [80/110]	Batch [10/120]	Loss 2.6106 (2.5692)	Prec@1 45.3125 (41.0511)
Epoch [80/110]	Batch [20/120]	Loss 2.4375 (2.4997)	Prec@1 40.6250 (42.2619)
Epoch [80/110]	Batch [30/120]	Loss 2.9117 (2.4921)	Prec@1 32.8125 (42.0867)
Epoch [80/110]	Batch [40/120]	Loss 2.1013 (2.4688)	Prec@1 53.1250 (42.4924)
Epoch [80/110]	Batch [50/120]	Loss 2.9168 (2.4941)	Prec@1 39.0625 (42.0650)
Epoch [80/110]	Batch [60/120]	Loss 2.4851 (2.5055)	Prec@1 42.1875 (41.4703)
Epoch [80/110]	Batch [70/120]	Loss 2.4783 (2.4943)	Prec@1 42.1875 (41.7474)
Epoch [80/110]	Batch [80/120]	Loss 2.5910 (2.5049)	Prec@1 34.3750 (41.4159)
Epoch [80/110]	Batch [90/120]	Loss 2.2871 (2.4999)	Prec@1 40.6250 (41.4663)
Epoch [80/110]	Batch [100/120]	Loss 2.6208 (2.5033)	Prec@1 34.3750 (41.3676)
Epoch [80/110]	Batch [110/120]	Loss 2.7804 (2.5165)	Prec@1 42.1875 (41.1458)
Training Time 70.5062191486
test accuracy
Epoch [80/110]	Loss 4.8902 (6.9065)	Prec@1 14.0625 (24.8828)
Epoch [81/110]	Batch [0/120]	Loss 3.0112 (3.0112)	Prec@1 34.3750 (34.3750)
Epoch [81/110]	Batch [10/120]	Loss 2.4497 (2.5804)	Prec@1 35.9375 (37.0739)
Epoch [81/110]	Batch [20/120]	Loss 2.7509 (2.6347)	Prec@1 34.3750 (36.6071)
Epoch [81/110]	Batch [30/120]	Loss 2.3077 (2.5769)	Prec@1 43.7500 (38.6593)
Epoch [81/110]	Batch [40/120]	Loss 2.4791 (2.5604)	Prec@1 42.1875 (38.6052)
Epoch [81/110]	Batch [50/120]	Loss 2.0189 (2.5581)	Prec@1 53.1250 (38.9706)
Epoch [81/110]	Batch [60/120]	Loss 2.2630 (2.5563)	Prec@1 48.4375 (39.8053)
Epoch [81/110]	Batch [70/120]	Loss 2.5231 (2.5506)	Prec@1 34.3750 (39.9648)
Epoch [81/110]	Batch [80/120]	Loss 2.3768 (2.5438)	Prec@1 40.6250 (40.3549)
Epoch [81/110]	Batch [90/120]	Loss 2.0984 (2.5307)	Prec@1 54.6875 (40.8139)
Epoch [81/110]	Batch [100/120]	Loss 2.3657 (2.5232)	Prec@1 45.3125 (41.0582)
Epoch [81/110]	Batch [110/120]	Loss 2.2518 (2.5182)	Prec@1 48.4375 (41.2725)
Training Time 68.6965279579
test accuracy
Epoch [81/110]	Loss 4.1844 (7.0767)	Prec@1 28.1250 (24.7461)
Epoch [82/110]	Batch [0/120]	Loss 2.4324 (2.4324)	Prec@1 45.3125 (45.3125)
Epoch [82/110]	Batch [10/120]	Loss 2.3845 (2.3416)	Prec@1 48.4375 (45.4545)
Epoch [82/110]	Batch [20/120]	Loss 2.1610 (2.4622)	Prec@1 48.4375 (41.8155)
Epoch [82/110]	Batch [30/120]	Loss 2.9917 (2.4839)	Prec@1 21.8750 (41.2802)
Epoch [82/110]	Batch [40/120]	Loss 2.3861 (2.4871)	Prec@1 45.3125 (41.3491)
Epoch [82/110]	Batch [50/120]	Loss 2.4944 (2.5021)	Prec@1 42.1875 (41.0846)
Epoch [82/110]	Batch [60/120]	Loss 2.3632 (2.5040)	Prec@1 45.3125 (41.4447)
Epoch [82/110]	Batch [70/120]	Loss 2.5350 (2.5218)	Prec@1 43.7500 (41.2192)
Epoch [82/110]	Batch [80/120]	Loss 2.4089 (2.5254)	Prec@1 56.2500 (41.5123)
Epoch [82/110]	Batch [90/120]	Loss 2.4672 (2.5308)	Prec@1 37.5000 (41.5350)
Epoch [82/110]	Batch [100/120]	Loss 2.2762 (2.5200)	Prec@1 48.4375 (41.7543)
Epoch [82/110]	Batch [110/120]	Loss 2.7043 (2.5244)	Prec@1 37.5000 (41.7793)
Training Time 70.8221361637
test accuracy
Epoch [82/110]	Loss 4.9012 (4.8385)	Prec@1 40.6250 (25.2148)
Epoch [83/110]	Batch [0/120]	Loss 2.5701 (2.5701)	Prec@1 39.0625 (39.0625)
Epoch [83/110]	Batch [10/120]	Loss 2.6083 (2.4835)	Prec@1 35.9375 (40.0568)
Epoch [83/110]	Batch [20/120]	Loss 2.6309 (2.4842)	Prec@1 39.0625 (41.6667)
Epoch [83/110]	Batch [30/120]	Loss 2.6858 (2.4614)	Prec@1 34.3750 (41.9355)
Epoch [83/110]	Batch [40/120]	Loss 2.6227 (2.4823)	Prec@1 40.6250 (42.0351)
Epoch [83/110]	Batch [50/120]	Loss 2.4483 (2.4934)	Prec@1 40.6250 (41.8811)
Epoch [83/110]	Batch [60/120]	Loss 2.1699 (2.4889)	Prec@1 48.4375 (41.9570)
Epoch [83/110]	Batch [70/120]	Loss 2.4937 (2.4783)	Prec@1 48.4375 (42.3415)
Epoch [83/110]	Batch [80/120]	Loss 2.5773 (2.4870)	Prec@1 40.6250 (42.0332)
Epoch [83/110]	Batch [90/120]	Loss 2.5425 (2.4876)	Prec@1 35.9375 (41.7582)
Epoch [83/110]	Batch [100/120]	Loss 2.5403 (2.4933)	Prec@1 35.9375 (41.5842)
Epoch [83/110]	Batch [110/120]	Loss 2.2841 (2.4938)	Prec@1 43.7500 (41.6385)
Training Time 69.8364679813
test accuracy
Epoch [83/110]	Loss 3.9705 (8.1619)	Prec@1 21.8750 (24.7852)
Epoch [84/110]	Batch [0/120]	Loss 2.3768 (2.3768)	Prec@1 43.7500 (43.7500)
Epoch [84/110]	Batch [10/120]	Loss 2.5682 (2.4804)	Prec@1 39.0625 (43.0398)
Epoch [84/110]	Batch [20/120]	Loss 2.3927 (2.4383)	Prec@1 40.6250 (43.2292)
Epoch [84/110]	Batch [30/120]	Loss 2.4046 (2.4427)	Prec@1 50.0000 (44.0020)
Epoch [84/110]	Batch [40/120]	Loss 2.3277 (2.4608)	Prec@1 45.3125 (43.2165)
Epoch [84/110]	Batch [50/120]	Loss 2.7231 (2.4695)	Prec@1 34.3750 (43.0760)
Epoch [84/110]	Batch [60/120]	Loss 2.4114 (2.4830)	Prec@1 48.4375 (42.6486)
Epoch [84/110]	Batch [70/120]	Loss 2.6514 (2.4758)	Prec@1 35.9375 (42.6496)
Epoch [84/110]	Batch [80/120]	Loss 2.7711 (2.4815)	Prec@1 40.6250 (42.5540)
Epoch [84/110]	Batch [90/120]	Loss 2.5292 (2.4844)	Prec@1 37.5000 (42.4107)
Epoch [84/110]	Batch [100/120]	Loss 2.5180 (2.4942)	Prec@1 37.5000 (42.0328)
Epoch [84/110]	Batch [110/120]	Loss 2.6750 (2.5029)	Prec@1 34.3750 (41.7652)
Training Time 68.3368480206
test accuracy
Epoch [84/110]	Loss 4.6031 (5.6836)	Prec@1 29.6875 (25.0391)
Epoch [85/110]	Batch [0/120]	Loss 2.1823 (2.1823)	Prec@1 40.6250 (40.6250)
Epoch [85/110]	Batch [10/120]	Loss 3.2600 (2.5472)	Prec@1 25.0000 (40.1989)
Epoch [85/110]	Batch [20/120]	Loss 3.0923 (2.4972)	Prec@1 37.5000 (42.2619)
Epoch [85/110]	Batch [30/120]	Loss 2.7802 (2.5199)	Prec@1 37.5000 (41.3306)
Epoch [85/110]	Batch [40/120]	Loss 2.6344 (2.5251)	Prec@1 35.9375 (40.8918)
Epoch [85/110]	Batch [50/120]	Loss 2.5468 (2.5246)	Prec@1 45.3125 (40.3799)
Epoch [85/110]	Batch [60/120]	Loss 2.2647 (2.5221)	Prec@1 51.5625 (40.8555)
Epoch [85/110]	Batch [70/120]	Loss 2.8624 (2.5224)	Prec@1 40.6250 (41.1532)
Epoch [85/110]	Batch [80/120]	Loss 2.1337 (2.5024)	Prec@1 51.5625 (41.5895)
Epoch [85/110]	Batch [90/120]	Loss 2.1855 (2.4982)	Prec@1 54.6875 (41.4835)
Epoch [85/110]	Batch [100/120]	Loss 2.4001 (2.4976)	Prec@1 48.4375 (41.5377)
Epoch [85/110]	Batch [110/120]	Loss 2.2938 (2.4986)	Prec@1 40.6250 (41.5822)
Training Time 69.0578439236
test accuracy
Epoch [85/110]	Loss 3.1584 (7.1751)	Prec@1 32.8125 (24.7852)
Epoch [86/110]	Batch [0/120]	Loss 2.4436 (2.4436)	Prec@1 42.1875 (42.1875)
Epoch [86/110]	Batch [10/120]	Loss 2.6203 (2.4900)	Prec@1 35.9375 (41.7614)
Epoch [86/110]	Batch [20/120]	Loss 2.7408 (2.5133)	Prec@1 43.7500 (42.2619)
Epoch [86/110]	Batch [30/120]	Loss 2.3189 (2.5259)	Prec@1 50.0000 (41.8347)
Epoch [86/110]	Batch [40/120]	Loss 2.4371 (2.5186)	Prec@1 46.8750 (42.0732)
Epoch [86/110]	Batch [50/120]	Loss 2.3103 (2.5215)	Prec@1 48.4375 (41.7279)
Epoch [86/110]	Batch [60/120]	Loss 2.6223 (2.5189)	Prec@1 40.6250 (41.6240)
Epoch [86/110]	Batch [70/120]	Loss 2.2407 (2.5123)	Prec@1 48.4375 (41.7914)
Epoch [86/110]	Batch [80/120]	Loss 2.5757 (2.4983)	Prec@1 46.8750 (42.0332)
Epoch [86/110]	Batch [90/120]	Loss 2.4737 (2.4871)	Prec@1 39.0625 (42.1703)
Epoch [86/110]	Batch [100/120]	Loss 2.3539 (2.4945)	Prec@1 34.3750 (41.8472)
Epoch [86/110]	Batch [110/120]	Loss 2.4820 (2.4886)	Prec@1 46.8750 (42.0749)
Training Time 68.2588310242
test accuracy
Epoch [86/110]	Loss 4.4984 (5.6594)	Prec@1 26.5625 (25.2344)
Epoch [87/110]	Batch [0/120]	Loss 2.1713 (2.1713)	Prec@1 46.8750 (46.8750)
Epoch [87/110]	Batch [10/120]	Loss 2.6649 (2.4114)	Prec@1 43.7500 (45.3125)
Epoch [87/110]	Batch [20/120]	Loss 2.3593 (2.5205)	Prec@1 40.6250 (43.3036)
Epoch [87/110]	Batch [30/120]	Loss 2.7274 (2.4986)	Prec@1 43.7500 (42.6411)
Epoch [87/110]	Batch [40/120]	Loss 2.5798 (2.4916)	Prec@1 43.7500 (42.6067)
Epoch [87/110]	Batch [50/120]	Loss 2.5082 (2.4735)	Prec@1 35.9375 (43.4743)
Epoch [87/110]	Batch [60/120]	Loss 2.4838 (2.4819)	Prec@1 45.3125 (43.4170)
Epoch [87/110]	Batch [70/120]	Loss 2.7218 (2.4840)	Prec@1 31.2500 (43.0018)
Epoch [87/110]	Batch [80/120]	Loss 2.3636 (2.4841)	Prec@1 37.5000 (42.7083)
Epoch [87/110]	Batch [90/120]	Loss 2.3390 (2.4897)	Prec@1 37.5000 (42.3935)
Epoch [87/110]	Batch [100/120]	Loss 2.3825 (2.4933)	Prec@1 42.1875 (42.3422)
Epoch [87/110]	Batch [110/120]	Loss 2.5547 (2.4955)	Prec@1 45.3125 (42.1453)
Training Time 69.4420349598
test accuracy
Epoch [87/110]	Loss 5.3077 (4.5036)	Prec@1 25.0000 (25.0000)
Epoch [88/110]	Batch [0/120]	Loss 2.6645 (2.6645)	Prec@1 34.3750 (34.3750)
Epoch [88/110]	Batch [10/120]	Loss 2.3374 (2.4484)	Prec@1 37.5000 (43.0398)
Epoch [88/110]	Batch [20/120]	Loss 2.4430 (2.4616)	Prec@1 45.3125 (43.1548)
Epoch [88/110]	Batch [30/120]	Loss 2.2799 (2.4567)	Prec@1 39.0625 (43.1452)
Epoch [88/110]	Batch [40/120]	Loss 2.5229 (2.4690)	Prec@1 40.6250 (42.7210)
Epoch [88/110]	Batch [50/120]	Loss 2.6405 (2.4577)	Prec@1 37.5000 (42.9228)
Epoch [88/110]	Batch [60/120]	Loss 2.3551 (2.4617)	Prec@1 39.0625 (42.6230)
Epoch [88/110]	Batch [70/120]	Loss 2.7633 (2.4590)	Prec@1 35.9375 (42.6276)
Epoch [88/110]	Batch [80/120]	Loss 2.4122 (2.4638)	Prec@1 43.7500 (42.5733)
Epoch [88/110]	Batch [90/120]	Loss 2.3899 (2.4710)	Prec@1 46.8750 (42.4794)
Epoch [88/110]	Batch [100/120]	Loss 2.6650 (2.4701)	Prec@1 40.6250 (42.6207)
Epoch [88/110]	Batch [110/120]	Loss 2.4799 (2.4834)	Prec@1 43.7500 (42.3142)
Training Time 69.7127969265
test accuracy
Epoch [88/110]	Loss 3.2579 (5.8901)	Prec@1 29.6875 (24.7656)
Epoch [89/110]	Batch [0/120]	Loss 2.5563 (2.5563)	Prec@1 39.0625 (39.0625)
Epoch [89/110]	Batch [10/120]	Loss 2.6484 (2.5615)	Prec@1 40.6250 (39.7727)
Epoch [89/110]	Batch [20/120]	Loss 2.4522 (2.4948)	Prec@1 42.1875 (40.6994)
Epoch [89/110]	Batch [30/120]	Loss 2.4547 (2.4727)	Prec@1 53.1250 (41.8851)
Epoch [89/110]	Batch [40/120]	Loss 2.8530 (2.4691)	Prec@1 31.2500 (42.1875)
Epoch [89/110]	Batch [50/120]	Loss 2.2368 (2.4839)	Prec@1 46.8750 (42.0956)
Epoch [89/110]	Batch [60/120]	Loss 2.4770 (2.4769)	Prec@1 39.0625 (42.2643)
Epoch [89/110]	Batch [70/120]	Loss 2.7923 (2.4757)	Prec@1 40.6250 (42.3856)
Epoch [89/110]	Batch [80/120]	Loss 2.8720 (2.4804)	Prec@1 34.3750 (42.1682)
Epoch [89/110]	Batch [90/120]	Loss 2.7688 (2.4819)	Prec@1 34.3750 (42.2047)
Epoch [89/110]	Batch [100/120]	Loss 2.6804 (2.4901)	Prec@1 32.8125 (42.0637)
Epoch [89/110]	Batch [110/120]	Loss 2.2018 (2.4950)	Prec@1 50.0000 (42.0467)
Training Time 70.4627377987
test accuracy
Epoch [89/110]	Loss 3.6825 (6.8421)	Prec@1 26.5625 (24.7461)
Epoch [90/110]	Batch [0/120]	Loss 2.6245 (2.6245)	Prec@1 37.5000 (37.5000)
Epoch [90/110]	Batch [10/120]	Loss 2.1737 (2.5208)	Prec@1 48.4375 (40.0568)
Epoch [90/110]	Batch [20/120]	Loss 2.1367 (2.4903)	Prec@1 45.3125 (41.6667)
Epoch [90/110]	Batch [30/120]	Loss 2.4206 (2.4931)	Prec@1 45.3125 (42.8427)
Epoch [90/110]	Batch [40/120]	Loss 2.5143 (2.5121)	Prec@1 37.5000 (42.3399)
Epoch [90/110]	Batch [50/120]	Loss 2.5946 (2.4965)	Prec@1 39.0625 (42.3407)
Epoch [90/110]	Batch [60/120]	Loss 2.6608 (2.4989)	Prec@1 37.5000 (42.1619)
Epoch [90/110]	Batch [70/120]	Loss 2.4687 (2.5006)	Prec@1 42.1875 (42.2535)
Epoch [90/110]	Batch [80/120]	Loss 2.5571 (2.4933)	Prec@1 45.3125 (42.4769)
Epoch [90/110]	Batch [90/120]	Loss 2.2712 (2.4810)	Prec@1 37.5000 (42.4966)
Epoch [90/110]	Batch [100/120]	Loss 2.7575 (2.4831)	Prec@1 34.3750 (42.3886)
Epoch [90/110]	Batch [110/120]	Loss 2.4454 (2.4798)	Prec@1 48.4375 (42.1593)
Training Time 71.1362369061
test accuracy
Epoch [90/110]	Loss 3.8208 (6.0391)	Prec@1 25.0000 (24.9805)
Epoch [91/110]	Batch [0/120]	Loss 2.8192 (2.8192)	Prec@1 35.9375 (35.9375)
Epoch [91/110]	Batch [10/120]	Loss 2.9522 (2.5647)	Prec@1 34.3750 (39.3466)
Epoch [91/110]	Batch [20/120]	Loss 2.2665 (2.5054)	Prec@1 45.3125 (40.4018)
Epoch [91/110]	Batch [30/120]	Loss 2.7284 (2.4999)	Prec@1 40.6250 (41.2298)
Epoch [91/110]	Batch [40/120]	Loss 2.6342 (2.4891)	Prec@1 45.3125 (41.3110)
Epoch [91/110]	Batch [50/120]	Loss 2.4393 (2.5081)	Prec@1 46.8750 (41.1765)
Epoch [91/110]	Batch [60/120]	Loss 2.7351 (2.5170)	Prec@1 35.9375 (40.6250)
Epoch [91/110]	Batch [70/120]	Loss 2.3239 (2.5109)	Prec@1 48.4375 (40.8451)
Epoch [91/110]	Batch [80/120]	Loss 2.5322 (2.5200)	Prec@1 34.3750 (40.5671)
Epoch [91/110]	Batch [90/120]	Loss 2.7178 (2.5212)	Prec@1 43.7500 (40.6765)
Epoch [91/110]	Batch [100/120]	Loss 2.4519 (2.5161)	Prec@1 40.6250 (41.1819)
Epoch [91/110]	Batch [110/120]	Loss 2.7932 (2.5126)	Prec@1 37.5000 (41.4133)
Training Time 70.2674422264
test accuracy
Epoch [91/110]	Loss 3.4936 (5.5980)	Prec@1 29.6875 (25.0781)
Epoch [92/110]	Batch [0/120]	Loss 2.9277 (2.9277)	Prec@1 37.5000 (37.5000)
Epoch [92/110]	Batch [10/120]	Loss 2.3565 (2.5893)	Prec@1 43.7500 (42.8977)
Epoch [92/110]	Batch [20/120]	Loss 2.6799 (2.5308)	Prec@1 37.5000 (43.5268)
Epoch [92/110]	Batch [30/120]	Loss 2.4453 (2.5239)	Prec@1 43.7500 (42.5403)
Epoch [92/110]	Batch [40/120]	Loss 2.0500 (2.5021)	Prec@1 56.2500 (42.6448)
Epoch [92/110]	Batch [50/120]	Loss 2.5889 (2.4777)	Prec@1 46.8750 (43.1679)
Epoch [92/110]	Batch [60/120]	Loss 2.9597 (2.4893)	Prec@1 32.8125 (42.8023)
Epoch [92/110]	Batch [70/120]	Loss 2.5778 (2.4794)	Prec@1 42.1875 (43.0898)
Epoch [92/110]	Batch [80/120]	Loss 2.3731 (2.4950)	Prec@1 40.6250 (42.6890)
Epoch [92/110]	Batch [90/120]	Loss 2.3681 (2.5068)	Prec@1 45.3125 (42.3420)
Epoch [92/110]	Batch [100/120]	Loss 2.4053 (2.4963)	Prec@1 53.1250 (42.4350)
Epoch [92/110]	Batch [110/120]	Loss 2.7022 (2.5071)	Prec@1 43.7500 (42.3423)
Training Time 69.8568139076
test accuracy
Epoch [92/110]	Loss 4.1489 (5.6070)	Prec@1 14.0625 (24.9023)
Epoch [93/110]	Batch [0/120]	Loss 2.8496 (2.8496)	Prec@1 39.0625 (39.0625)
Epoch [93/110]	Batch [10/120]	Loss 2.6136 (2.5786)	Prec@1 39.0625 (43.1818)
Epoch [93/110]	Batch [20/120]	Loss 2.7728 (2.5434)	Prec@1 40.6250 (43.0804)
Epoch [93/110]	Batch [30/120]	Loss 2.0376 (2.5369)	Prec@1 56.2500 (42.9435)
Epoch [93/110]	Batch [40/120]	Loss 2.6445 (2.5449)	Prec@1 37.5000 (42.3780)
Epoch [93/110]	Batch [50/120]	Loss 2.6713 (2.5194)	Prec@1 42.1875 (42.8002)
Epoch [93/110]	Batch [60/120]	Loss 2.2807 (2.5175)	Prec@1 48.4375 (42.5461)
Epoch [93/110]	Batch [70/120]	Loss 2.4986 (2.5263)	Prec@1 37.5000 (42.3856)
Epoch [93/110]	Batch [80/120]	Loss 2.6523 (2.5172)	Prec@1 35.9375 (42.3804)
Epoch [93/110]	Batch [90/120]	Loss 1.7090 (2.5025)	Prec@1 56.2500 (42.5481)
Epoch [93/110]	Batch [100/120]	Loss 2.5738 (2.5042)	Prec@1 43.7500 (42.4196)
Epoch [93/110]	Batch [110/120]	Loss 2.2611 (2.5044)	Prec@1 42.1875 (42.4127)
Training Time 69.3914260864
test accuracy
Epoch [93/110]	Loss 3.4821 (5.2615)	Prec@1 25.0000 (25.5273)
Saving..
Epoch [94/110]	Batch [0/120]	Loss 2.6214 (2.6214)	Prec@1 40.6250 (40.6250)
Epoch [94/110]	Batch [10/120]	Loss 2.3390 (2.5116)	Prec@1 43.7500 (40.4830)
Epoch [94/110]	Batch [20/120]	Loss 2.3953 (2.4778)	Prec@1 48.4375 (42.2619)
Epoch [94/110]	Batch [30/120]	Loss 2.0503 (2.4755)	Prec@1 48.4375 (42.6915)
Epoch [94/110]	Batch [40/120]	Loss 2.4889 (2.4810)	Prec@1 46.8750 (42.7973)
Epoch [94/110]	Batch [50/120]	Loss 2.3867 (2.4712)	Prec@1 45.3125 (43.1985)
Epoch [94/110]	Batch [60/120]	Loss 2.3391 (2.4732)	Prec@1 46.8750 (43.1865)
Epoch [94/110]	Batch [70/120]	Loss 2.2203 (2.4564)	Prec@1 48.4375 (43.6400)
Epoch [94/110]	Batch [80/120]	Loss 2.8593 (2.4593)	Prec@1 34.3750 (43.4221)
Epoch [94/110]	Batch [90/120]	Loss 2.6142 (2.4703)	Prec@1 43.7500 (43.2521)
Epoch [94/110]	Batch [100/120]	Loss 2.3894 (2.4680)	Prec@1 42.1875 (43.2550)
Epoch [94/110]	Batch [110/120]	Loss 2.0733 (2.4662)	Prec@1 53.1250 (43.2292)
Training Time 69.4274280071
test accuracy
Epoch [94/110]	Loss 4.8286 (6.6819)	Prec@1 21.8750 (24.9023)
Epoch [95/110]	Batch [0/120]	Loss 2.2462 (2.2462)	Prec@1 50.0000 (50.0000)
Epoch [95/110]	Batch [10/120]	Loss 2.4709 (2.4351)	Prec@1 45.3125 (45.0284)
Epoch [95/110]	Batch [20/120]	Loss 2.8359 (2.5110)	Prec@1 34.3750 (42.9315)
Epoch [95/110]	Batch [30/120]	Loss 2.1051 (2.5096)	Prec@1 53.1250 (42.7419)
Epoch [95/110]	Batch [40/120]	Loss 2.6694 (2.4950)	Prec@1 40.6250 (42.8735)
Epoch [95/110]	Batch [50/120]	Loss 2.2036 (2.4693)	Prec@1 48.4375 (43.7194)
Epoch [95/110]	Batch [60/120]	Loss 2.4823 (2.4695)	Prec@1 37.5000 (43.6475)
Epoch [95/110]	Batch [70/120]	Loss 2.2200 (2.4638)	Prec@1 43.7500 (43.4639)
Epoch [95/110]	Batch [80/120]	Loss 2.4013 (2.4669)	Prec@1 50.0000 (43.2292)
Epoch [95/110]	Batch [90/120]	Loss 2.5317 (2.4764)	Prec@1 39.0625 (42.8915)
Epoch [95/110]	Batch [100/120]	Loss 2.8197 (2.4786)	Prec@1 39.0625 (42.9920)
Epoch [95/110]	Batch [110/120]	Loss 2.2966 (2.4752)	Prec@1 48.4375 (43.1588)
Training Time 69.3708610535
test accuracy
Epoch [95/110]	Loss 10.3287 (4.2530)	Prec@1 28.1250 (25.7031)
Saving..
Epoch [96/110]	Batch [0/120]	Loss 2.9057 (2.9057)	Prec@1 26.5625 (26.5625)
Epoch [96/110]	Batch [10/120]	Loss 2.3176 (2.5006)	Prec@1 48.4375 (42.1875)
Epoch [96/110]	Batch [20/120]	Loss 2.1818 (2.4850)	Prec@1 39.0625 (42.1875)
Epoch [96/110]	Batch [30/120]	Loss 2.1736 (2.4198)	Prec@1 45.3125 (43.2964)
Epoch [96/110]	Batch [40/120]	Loss 2.9483 (2.4431)	Prec@1 37.5000 (43.2927)
Epoch [96/110]	Batch [50/120]	Loss 2.3329 (2.4423)	Prec@1 48.4375 (43.5355)
Epoch [96/110]	Batch [60/120]	Loss 2.5628 (2.4540)	Prec@1 35.9375 (43.0840)
Epoch [96/110]	Batch [70/120]	Loss 2.5488 (2.4715)	Prec@1 34.3750 (42.8037)
Epoch [96/110]	Batch [80/120]	Loss 2.3978 (2.4691)	Prec@1 43.7500 (43.0170)
Epoch [96/110]	Batch [90/120]	Loss 2.5349 (2.4662)	Prec@1 48.4375 (43.0460)
Epoch [96/110]	Batch [100/120]	Loss 2.4172 (2.4653)	Prec@1 48.4375 (43.0384)
Epoch [96/110]	Batch [110/120]	Loss 2.3657 (2.4700)	Prec@1 50.0000 (42.9476)
Training Time 69.0426709652
test accuracy
Epoch [96/110]	Loss 3.5667 (5.0789)	Prec@1 29.6875 (25.1172)
Epoch [97/110]	Batch [0/120]	Loss 2.6669 (2.6669)	Prec@1 32.8125 (32.8125)
Epoch [97/110]	Batch [10/120]	Loss 2.2204 (2.4799)	Prec@1 54.6875 (42.8977)
Epoch [97/110]	Batch [20/120]	Loss 2.2862 (2.4724)	Prec@1 48.4375 (43.6012)
Epoch [97/110]	Batch [30/120]	Loss 2.4326 (2.4396)	Prec@1 46.8750 (43.9012)
Epoch [97/110]	Batch [40/120]	Loss 2.3745 (2.4389)	Prec@1 39.0625 (43.9405)
Epoch [97/110]	Batch [50/120]	Loss 2.9234 (2.4550)	Prec@1 31.2500 (43.1679)
Epoch [97/110]	Batch [60/120]	Loss 2.6441 (2.4796)	Prec@1 32.8125 (42.1875)
Epoch [97/110]	Batch [70/120]	Loss 2.4348 (2.4795)	Prec@1 37.5000 (42.0335)
Epoch [97/110]	Batch [80/120]	Loss 2.3501 (2.4892)	Prec@1 50.0000 (41.9367)
Epoch [97/110]	Batch [90/120]	Loss 2.4830 (2.5034)	Prec@1 42.1875 (41.5865)
Epoch [97/110]	Batch [100/120]	Loss 2.4541 (2.4972)	Prec@1 43.7500 (41.8007)
Epoch [97/110]	Batch [110/120]	Loss 2.4814 (2.5036)	Prec@1 42.1875 (41.8637)
Training Time 69.6446409225
test accuracy
Epoch [97/110]	Loss 7.1904 (5.5064)	Prec@1 20.3125 (24.7070)
Epoch [98/110]	Batch [0/120]	Loss 2.7959 (2.7959)	Prec@1 37.5000 (37.5000)
Epoch [98/110]	Batch [10/120]	Loss 2.2481 (2.4076)	Prec@1 37.5000 (44.3182)
Epoch [98/110]	Batch [20/120]	Loss 2.5771 (2.4085)	Prec@1 32.8125 (43.3036)
Epoch [98/110]	Batch [30/120]	Loss 2.3959 (2.4297)	Prec@1 46.8750 (43.2964)
Epoch [98/110]	Batch [40/120]	Loss 2.4900 (2.4376)	Prec@1 42.1875 (43.4451)
Epoch [98/110]	Batch [50/120]	Loss 2.5145 (2.4294)	Prec@1 42.1875 (43.6581)
Epoch [98/110]	Batch [60/120]	Loss 2.5298 (2.4373)	Prec@1 43.7500 (43.4426)
Epoch [98/110]	Batch [70/120]	Loss 2.7848 (2.4460)	Prec@1 31.2500 (43.1118)
Epoch [98/110]	Batch [80/120]	Loss 2.1115 (2.4622)	Prec@1 43.7500 (42.5926)
Epoch [98/110]	Batch [90/120]	Loss 2.1236 (2.4602)	Prec@1 51.5625 (42.7198)
Epoch [98/110]	Batch [100/120]	Loss 2.3244 (2.4610)	Prec@1 42.1875 (42.7135)
Epoch [98/110]	Batch [110/120]	Loss 2.7286 (2.4665)	Prec@1 39.0625 (42.6661)
Training Time 70.4118599892
test accuracy
Epoch [98/110]	Loss 8.9602 (6.1487)	Prec@1 18.7500 (24.9805)
Epoch [99/110]	Batch [0/120]	Loss 2.3616 (2.3616)	Prec@1 48.4375 (48.4375)
Epoch [99/110]	Batch [10/120]	Loss 2.7389 (2.4636)	Prec@1 40.6250 (43.7500)
Epoch [99/110]	Batch [20/120]	Loss 2.4262 (2.4362)	Prec@1 46.8750 (43.3780)
Epoch [99/110]	Batch [30/120]	Loss 2.2554 (2.4515)	Prec@1 45.3125 (43.5484)
Epoch [99/110]	Batch [40/120]	Loss 2.0967 (2.4452)	Prec@1 51.5625 (43.3689)
Epoch [99/110]	Batch [50/120]	Loss 2.1095 (2.4448)	Prec@1 42.1875 (43.3211)
Epoch [99/110]	Batch [60/120]	Loss 2.8264 (2.4686)	Prec@1 32.8125 (42.8279)
Epoch [99/110]	Batch [70/120]	Loss 2.3761 (2.4650)	Prec@1 43.7500 (42.7377)
Epoch [99/110]	Batch [80/120]	Loss 2.4635 (2.4783)	Prec@1 42.1875 (42.4769)
Epoch [99/110]	Batch [90/120]	Loss 2.4310 (2.4667)	Prec@1 45.3125 (43.0632)
Epoch [99/110]	Batch [100/120]	Loss 2.4985 (2.4655)	Prec@1 39.0625 (43.1312)
Epoch [99/110]	Batch [110/120]	Loss 2.6751 (2.4744)	Prec@1 42.1875 (42.9054)
Training Time 70.2796339989
test accuracy
Epoch [99/110]	Loss 6.5943 (6.3130)	Prec@1 25.0000 (25.5469)
Epoch [100/110]	Batch [0/120]	Loss 2.6199 (2.6199)	Prec@1 35.9375 (35.9375)
Epoch [100/110]	Batch [10/120]	Loss 2.5672 (2.4599)	Prec@1 35.9375 (41.9034)
Epoch [100/110]	Batch [20/120]	Loss 2.4720 (2.4511)	Prec@1 42.1875 (42.6339)
Epoch [100/110]	Batch [30/120]	Loss 2.9069 (2.4671)	Prec@1 31.2500 (42.6915)
Epoch [100/110]	Batch [40/120]	Loss 2.6475 (2.4576)	Prec@1 37.5000 (42.6448)
Epoch [100/110]	Batch [50/120]	Loss 2.1044 (2.4568)	Prec@1 54.6875 (43.0147)
Epoch [100/110]	Batch [60/120]	Loss 2.2647 (2.4567)	Prec@1 46.8750 (43.3658)
Epoch [100/110]	Batch [70/120]	Loss 2.5857 (2.4574)	Prec@1 45.3125 (43.3979)
Epoch [100/110]	Batch [80/120]	Loss 2.3089 (2.4620)	Prec@1 39.0625 (42.8241)
Epoch [100/110]	Batch [90/120]	Loss 2.0994 (2.4703)	Prec@1 53.1250 (42.5137)
Epoch [100/110]	Batch [100/120]	Loss 2.5047 (2.4748)	Prec@1 45.3125 (42.4041)
Epoch [100/110]	Batch [110/120]	Loss 2.4672 (2.4766)	Prec@1 43.7500 (42.3986)
Training Time 69.0552680492
test accuracy
Epoch [100/110]	Loss 7.6568 (5.3789)	Prec@1 28.1250 (25.1562)
Epoch [101/110]	Batch [0/120]	Loss 2.3639 (2.3639)	Prec@1 43.7500 (43.7500)
Epoch [101/110]	Batch [10/120]	Loss 2.8428 (2.4401)	Prec@1 35.9375 (42.0455)
Epoch [101/110]	Batch [20/120]	Loss 2.3107 (2.4823)	Prec@1 45.3125 (42.6339)
Epoch [101/110]	Batch [30/120]	Loss 2.3856 (2.4775)	Prec@1 39.0625 (42.3387)
Epoch [101/110]	Batch [40/120]	Loss 2.5470 (2.4568)	Prec@1 43.7500 (43.3308)
Epoch [101/110]	Batch [50/120]	Loss 2.5538 (2.4619)	Prec@1 45.3125 (43.5049)
Epoch [101/110]	Batch [60/120]	Loss 2.6351 (2.4666)	Prec@1 40.6250 (43.7244)
Epoch [101/110]	Batch [70/120]	Loss 2.5661 (2.4757)	Prec@1 42.1875 (43.5519)
Epoch [101/110]	Batch [80/120]	Loss 2.4541 (2.4667)	Prec@1 34.3750 (43.6150)
Epoch [101/110]	Batch [90/120]	Loss 2.3398 (2.4705)	Prec@1 42.1875 (43.5440)
Epoch [101/110]	Batch [100/120]	Loss 2.2879 (2.4771)	Prec@1 53.1250 (43.3323)
Epoch [101/110]	Batch [110/120]	Loss 2.6065 (2.4777)	Prec@1 39.0625 (43.2855)
Training Time 68.6678929329
test accuracy
Epoch [101/110]	Loss 3.8020 (4.5571)	Prec@1 23.4375 (25.3906)
Epoch [102/110]	Batch [0/120]	Loss 2.7293 (2.7293)	Prec@1 39.0625 (39.0625)
Epoch [102/110]	Batch [10/120]	Loss 2.3855 (2.5646)	Prec@1 45.3125 (40.0568)
Epoch [102/110]	Batch [20/120]	Loss 2.2427 (2.5307)	Prec@1 53.1250 (40.6994)
Epoch [102/110]	Batch [30/120]	Loss 2.3575 (2.5130)	Prec@1 45.3125 (41.1290)
Epoch [102/110]	Batch [40/120]	Loss 2.7583 (2.5068)	Prec@1 39.0625 (41.8445)
Epoch [102/110]	Batch [50/120]	Loss 2.6990 (2.5479)	Prec@1 37.5000 (40.9314)
Epoch [102/110]	Batch [60/120]	Loss 2.8442 (2.5463)	Prec@1 37.5000 (40.9580)
Epoch [102/110]	Batch [70/120]	Loss 2.7779 (2.5599)	Prec@1 32.8125 (40.6910)
Epoch [102/110]	Batch [80/120]	Loss 2.5872 (2.5518)	Prec@1 43.7500 (40.8951)
Epoch [102/110]	Batch [90/120]	Loss 2.6548 (2.5324)	Prec@1 34.3750 (41.0714)
Epoch [102/110]	Batch [100/120]	Loss 2.5332 (2.5378)	Prec@1 40.6250 (41.0582)
Epoch [102/110]	Batch [110/120]	Loss 2.5636 (2.5373)	Prec@1 42.1875 (40.9347)
Training Time 68.9513618946
test accuracy
Epoch [102/110]	Loss 12.3158 (6.2290)	Prec@1 29.6875 (24.8438)
Epoch [103/110]	Batch [0/120]	Loss 2.3867 (2.3867)	Prec@1 40.6250 (40.6250)
Epoch [103/110]	Batch [10/120]	Loss 2.3145 (2.4560)	Prec@1 43.7500 (41.1932)
Epoch [103/110]	Batch [20/120]	Loss 2.4482 (2.4386)	Prec@1 40.6250 (43.1548)
Epoch [103/110]	Batch [30/120]	Loss 2.8485 (2.4777)	Prec@1 39.0625 (43.0948)
Epoch [103/110]	Batch [40/120]	Loss 2.5033 (2.4600)	Prec@1 42.1875 (43.5595)
Epoch [103/110]	Batch [50/120]	Loss 2.4019 (2.4537)	Prec@1 39.0625 (43.5355)
Epoch [103/110]	Batch [60/120]	Loss 2.9953 (2.4770)	Prec@1 31.2500 (43.1865)
Epoch [103/110]	Batch [70/120]	Loss 2.4442 (2.4873)	Prec@1 39.0625 (43.1558)
Epoch [103/110]	Batch [80/120]	Loss 2.4775 (2.4903)	Prec@1 48.4375 (43.1134)
Epoch [103/110]	Batch [90/120]	Loss 2.6719 (2.4927)	Prec@1 40.6250 (42.8228)
Epoch [103/110]	Batch [100/120]	Loss 2.4301 (2.4965)	Prec@1 45.3125 (42.6361)
Epoch [103/110]	Batch [110/120]	Loss 2.4038 (2.4911)	Prec@1 42.1875 (42.6098)
Training Time 69.3273229599
test accuracy
Epoch [103/110]	Loss 7.1578 (5.7023)	Prec@1 28.1250 (25.0586)
Epoch [104/110]	Batch [0/120]	Loss 2.1186 (2.1186)	Prec@1 51.5625 (51.5625)
Epoch [104/110]	Batch [10/120]	Loss 2.2834 (2.4542)	Prec@1 45.3125 (43.4659)
Epoch [104/110]	Batch [20/120]	Loss 2.0707 (2.4012)	Prec@1 59.3750 (45.3125)
Epoch [104/110]	Batch [30/120]	Loss 2.8153 (2.4403)	Prec@1 34.3750 (44.2540)
Epoch [104/110]	Batch [40/120]	Loss 2.4479 (2.4387)	Prec@1 42.1875 (44.1311)
Epoch [104/110]	Batch [50/120]	Loss 2.6789 (2.4328)	Prec@1 39.0625 (44.0257)
Epoch [104/110]	Batch [60/120]	Loss 2.5637 (2.4630)	Prec@1 35.9375 (43.5451)
Epoch [104/110]	Batch [70/120]	Loss 2.6043 (2.4754)	Prec@1 42.1875 (43.1338)
Epoch [104/110]	Batch [80/120]	Loss 2.6652 (2.4735)	Prec@1 42.1875 (42.9398)
Epoch [104/110]	Batch [90/120]	Loss 2.9071 (2.4783)	Prec@1 40.6250 (43.2005)
Epoch [104/110]	Batch [100/120]	Loss 2.8232 (2.4758)	Prec@1 40.6250 (43.3478)
Epoch [104/110]	Batch [110/120]	Loss 2.0706 (2.4807)	Prec@1 56.2500 (43.2995)
Training Time 69.1225430965
test accuracy
Epoch [104/110]	Loss 3.4150 (5.8013)	Prec@1 31.2500 (25.4688)
Epoch [105/110]	Batch [0/120]	Loss 2.2837 (2.2837)	Prec@1 45.3125 (45.3125)
Epoch [105/110]	Batch [10/120]	Loss 2.4353 (2.3167)	Prec@1 39.0625 (45.3125)
Epoch [105/110]	Batch [20/120]	Loss 2.5901 (2.4768)	Prec@1 34.3750 (41.6667)
Epoch [105/110]	Batch [30/120]	Loss 2.5814 (2.4766)	Prec@1 42.1875 (41.5827)
Epoch [105/110]	Batch [40/120]	Loss 2.3849 (2.4593)	Prec@1 45.3125 (42.2637)
Epoch [105/110]	Batch [50/120]	Loss 2.7968 (2.4825)	Prec@1 39.0625 (42.0956)
Epoch [105/110]	Batch [60/120]	Loss 2.5663 (2.4891)	Prec@1 39.0625 (42.4180)
Epoch [105/110]	Batch [70/120]	Loss 2.5954 (2.4823)	Prec@1 42.1875 (42.2755)
Epoch [105/110]	Batch [80/120]	Loss 2.1769 (2.4780)	Prec@1 51.5625 (42.3418)
Epoch [105/110]	Batch [90/120]	Loss 2.3769 (2.4706)	Prec@1 43.7500 (42.5996)
Epoch [105/110]	Batch [100/120]	Loss 2.6598 (2.4718)	Prec@1 39.0625 (42.6980)
Epoch [105/110]	Batch [110/120]	Loss 2.2953 (2.4612)	Prec@1 43.7500 (42.9476)
Training Time 68.3971459866
test accuracy
Epoch [105/110]	Loss 3.9974 (7.9182)	Prec@1 21.8750 (24.4922)
Epoch [106/110]	Batch [0/120]	Loss 2.3164 (2.3164)	Prec@1 45.3125 (45.3125)
Epoch [106/110]	Batch [10/120]	Loss 2.7768 (2.5934)	Prec@1 50.0000 (42.4716)
Epoch [106/110]	Batch [20/120]	Loss 2.3111 (2.5384)	Prec@1 43.7500 (43.0060)
Epoch [106/110]	Batch [30/120]	Loss 2.4659 (2.5148)	Prec@1 46.8750 (42.8931)
Epoch [106/110]	Batch [40/120]	Loss 2.7839 (2.4970)	Prec@1 31.2500 (42.9116)
Epoch [106/110]	Batch [50/120]	Loss 2.6008 (2.4952)	Prec@1 40.6250 (42.6777)
Epoch [106/110]	Batch [60/120]	Loss 2.2122 (2.4868)	Prec@1 54.6875 (42.9303)
Epoch [106/110]	Batch [70/120]	Loss 2.6543 (2.4887)	Prec@1 37.5000 (42.8037)
Epoch [106/110]	Batch [80/120]	Loss 2.4215 (2.4919)	Prec@1 45.3125 (42.9591)
Epoch [106/110]	Batch [90/120]	Loss 2.1122 (2.4910)	Prec@1 50.0000 (42.8915)
Epoch [106/110]	Batch [100/120]	Loss 2.5585 (2.4890)	Prec@1 45.3125 (42.9610)
Epoch [106/110]	Batch [110/120]	Loss 2.2253 (2.4896)	Prec@1 43.7500 (42.8069)
Training Time 68.7827129364
test accuracy
Epoch [106/110]	Loss 3.9685 (4.7312)	Prec@1 12.5000 (25.1758)
Epoch [107/110]	Batch [0/120]	Loss 2.5469 (2.5469)	Prec@1 39.0625 (39.0625)
Epoch [107/110]	Batch [10/120]	Loss 2.7280 (2.4524)	Prec@1 35.9375 (44.6023)
Epoch [107/110]	Batch [20/120]	Loss 2.4312 (2.3877)	Prec@1 39.0625 (44.7173)
Epoch [107/110]	Batch [30/120]	Loss 2.4264 (2.4209)	Prec@1 40.6250 (43.6492)
Epoch [107/110]	Batch [40/120]	Loss 2.3250 (2.4281)	Prec@1 45.3125 (42.5686)
Epoch [107/110]	Batch [50/120]	Loss 2.7494 (2.4493)	Prec@1 40.6250 (42.3100)
Epoch [107/110]	Batch [60/120]	Loss 2.2246 (2.4724)	Prec@1 53.1250 (42.4949)
Epoch [107/110]	Batch [70/120]	Loss 2.2758 (2.4620)	Prec@1 40.6250 (42.4076)
Epoch [107/110]	Batch [80/120]	Loss 2.6451 (2.4583)	Prec@1 34.3750 (42.3611)
Epoch [107/110]	Batch [90/120]	Loss 2.4346 (2.4571)	Prec@1 42.1875 (42.7370)
Epoch [107/110]	Batch [100/120]	Loss 2.3876 (2.4511)	Prec@1 39.0625 (42.8373)
Epoch [107/110]	Batch [110/120]	Loss 2.2014 (2.4522)	Prec@1 43.7500 (42.8350)
Training Time 69.4209671021
test accuracy
Epoch [107/110]	Loss 11.6295 (5.8187)	Prec@1 15.6250 (25.2148)
Epoch [108/110]	Batch [0/120]	Loss 2.5262 (2.5262)	Prec@1 45.3125 (45.3125)
Epoch [108/110]	Batch [10/120]	Loss 2.3798 (2.4460)	Prec@1 37.5000 (44.0341)
Epoch [108/110]	Batch [20/120]	Loss 2.4692 (2.4778)	Prec@1 46.8750 (42.2619)
Epoch [108/110]	Batch [30/120]	Loss 2.0980 (2.4417)	Prec@1 43.7500 (42.9435)
Epoch [108/110]	Batch [40/120]	Loss 2.4545 (2.4352)	Prec@1 37.5000 (42.6067)
Epoch [108/110]	Batch [50/120]	Loss 2.7482 (2.4558)	Prec@1 42.1875 (42.4326)
Epoch [108/110]	Batch [60/120]	Loss 2.5015 (2.4643)	Prec@1 40.6250 (42.2131)
Epoch [108/110]	Batch [70/120]	Loss 2.4224 (2.4603)	Prec@1 45.3125 (42.5396)
Epoch [108/110]	Batch [80/120]	Loss 2.5202 (2.4802)	Prec@1 43.7500 (42.3418)
Epoch [108/110]	Batch [90/120]	Loss 2.7271 (2.4845)	Prec@1 37.5000 (42.1703)
Epoch [108/110]	Batch [100/120]	Loss 2.3568 (2.4774)	Prec@1 42.1875 (42.5124)
Epoch [108/110]	Batch [110/120]	Loss 2.2442 (2.4820)	Prec@1 46.8750 (42.2860)
Training Time 68.7873950005
test accuracy
Epoch [108/110]	Loss 10.2246 (4.5294)	Prec@1 23.4375 (25.1758)
Epoch [109/110]	Batch [0/120]	Loss 2.5779 (2.5779)	Prec@1 46.8750 (46.8750)
Epoch [109/110]	Batch [10/120]	Loss 2.4023 (2.5345)	Prec@1 42.1875 (42.1875)
Epoch [109/110]	Batch [20/120]	Loss 2.4856 (2.4912)	Prec@1 40.6250 (43.4524)
Epoch [109/110]	Batch [30/120]	Loss 2.4498 (2.4701)	Prec@1 50.0000 (43.6996)
Epoch [109/110]	Batch [40/120]	Loss 2.5946 (2.4657)	Prec@1 43.7500 (43.4832)
Epoch [109/110]	Batch [50/120]	Loss 2.1319 (2.4629)	Prec@1 48.4375 (43.3517)
Epoch [109/110]	Batch [60/120]	Loss 2.1762 (2.4894)	Prec@1 48.4375 (42.2387)
Epoch [109/110]	Batch [70/120]	Loss 2.3474 (2.4989)	Prec@1 50.0000 (42.0555)
Epoch [109/110]	Batch [80/120]	Loss 2.5625 (2.4899)	Prec@1 37.5000 (42.2454)
Epoch [109/110]	Batch [90/120]	Loss 2.2666 (2.4831)	Prec@1 45.3125 (42.3935)
Epoch [109/110]	Batch [100/120]	Loss 2.7141 (2.4990)	Prec@1 34.3750 (42.2184)
Epoch [109/110]	Batch [110/120]	Loss 2.4934 (2.4974)	Prec@1 48.4375 (42.2720)
Training Time 69.3144760132
test accuracy
Epoch [109/110]	Loss 3.4523 (4.9539)	Prec@1 29.6875 (25.3516)
